{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../raw_data/df_grouped_rate.csv') #폴더 위치는 상이할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>code</th>\n",
       "      <th>s_store_no_of_store</th>\n",
       "      <th>s_store_no_of_opening</th>\n",
       "      <th>s_store_no_of_closing</th>\n",
       "      <th>s_work_female</th>\n",
       "      <th>s_float_male</th>\n",
       "      <th>s_float_female</th>\n",
       "      <th>b_facil_total</th>\n",
       "      <th>b_apt_avg_price</th>\n",
       "      <th>b_income_avg_monthly_inc</th>\n",
       "      <th>sales_weekday</th>\n",
       "      <th>sales_female</th>\n",
       "      <th>sales_2030s</th>\n",
       "      <th>sales_06_11</th>\n",
       "      <th>sales_11_14</th>\n",
       "      <th>sales_14_17</th>\n",
       "      <th>sales_17_21</th>\n",
       "      <th>sales_21_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000001</td>\n",
       "      <td>CS100001</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.707812</td>\n",
       "      <td>0.318123</td>\n",
       "      <td>0.341417</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.344443</td>\n",
       "      <td>0.164275</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>0.120878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000001</td>\n",
       "      <td>CS100002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.734836</td>\n",
       "      <td>0.340414</td>\n",
       "      <td>0.468521</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.447948</td>\n",
       "      <td>0.173301</td>\n",
       "      <td>0.363921</td>\n",
       "      <td>0.008290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "      <td>CS100003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>0.321958</td>\n",
       "      <td>0.480098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.057219</td>\n",
       "      <td>0.227561</td>\n",
       "      <td>0.182710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   district      code  s_store_no_of_store  s_store_no_of_opening  \\\n",
       "0   1000001  CS100001                 16.5                      2   \n",
       "1   1000001  CS100002                  2.0                      1   \n",
       "2   1000001  CS100003                  2.0                      0   \n",
       "\n",
       "   s_store_no_of_closing  s_work_female  s_float_male  s_float_female  \\\n",
       "0                      2           1748        211158          145498   \n",
       "1                      1           1748        211158          145498   \n",
       "2                      0           1748        211158          145498   \n",
       "\n",
       "   b_facil_total  b_apt_avg_price  b_income_avg_monthly_inc  sales_weekday  \\\n",
       "0          129.0      188530154.0                 3889111.0       0.707812   \n",
       "1          129.0      188530154.0                 3889111.0       0.734836   \n",
       "2          129.0      188530154.0                 3889111.0       0.914956   \n",
       "\n",
       "   sales_female  sales_2030s  sales_06_11  sales_11_14  sales_14_17  \\\n",
       "0      0.318123     0.341417     0.007379     0.344443     0.164275   \n",
       "1      0.340414     0.468521     0.006540     0.447948     0.173301   \n",
       "2      0.321958     0.480098     0.000000     0.524393     0.057219   \n",
       "\n",
       "   sales_17_21  sales_21_24  \n",
       "0     0.345822     0.120878  \n",
       "1     0.363921     0.008290  \n",
       "2     0.227561     0.182710  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,3:4]\n",
    "X= df.iloc[:,1:].drop(['sales_total'],axis=1)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['service'] = X['code'].apply(lambda x: x[2:3]).astype('object')\n",
    "X.drop(['code'],axis=1,inplace=True)\n",
    "X['district']=X['district'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s_store_no_of_store', 's_store_no_of_opening', 's_store_no_of_closing',\n",
       "       's_work_female', 's_float_male', 's_float_female', 'b_facil_total',\n",
       "       'b_apt_avg_price', 'b_income_avg_monthly_inc', 'sales_weekday',\n",
       "       ...\n",
       "       'district_1001001', 'district_1001002', 'district_1001003',\n",
       "       'district_1001004', 'district_1001005', 'district_1001006',\n",
       "       'district_1001007', 'district_1001008', 'district_1001009',\n",
       "       'district_1001010'],\n",
       "      dtype='object', length=1024)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더미변수화\n",
    "X_dum = pd.get_dummies(X)  #district는 범주형으로 인식 안해서 따로 실시\n",
    "X_dum.columns[:-3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치형 데이터만 했을때\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s_store_no_of_opening', 's_store_no_of_closing', 's_work_female',\n",
       "       's_float_male', 's_float_female', 'b_facil_total', 'b_apt_avg_price',\n",
       "       'b_income_avg_monthly_inc', 'sales_weekday', 'sales_female',\n",
       "       'sales_2030s', 'sales_06_11', 'sales_11_14', 'sales_14_17',\n",
       "       'sales_17_21', 'sales_21_24', 'service'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.iloc[:,2:], y, test_size=0.2, random_state=50) \n",
    "\n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "Xs_train = rb.fit_transform(X_train)\n",
    "Xs_test = rb.transform(X_test)\n",
    "\n",
    "# 회귀분석\n",
    "regressor = LinearRegression()\n",
    "model = regressor.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22155144176456223\n",
      "0.21853148234594\n",
      "==================================================\n",
      "==================================================\n",
      "R-Square:  0.21853148234594\n",
      "Mean Absolute Error: 756985057.0958046\n",
      "Mean Squared Error: 2.438809704554385e+18\n",
      "Root Mean Squared Error: 1561668884.4164069\n"
     ]
    }
   ],
   "source": [
    "# 정확도 결과값\n",
    "print(model.score(Xs_train, y_train))\n",
    "print(model.score(Xs_test, y_test))\n",
    "\n",
    "print('='*50)\n",
    "print('='*50)\n",
    "# 오차 결과값\n",
    "from sklearn import metrics\n",
    "y_pred = model.predict(Xs_test)\n",
    "print('R-Square: ',r2_score(y_test , y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:            sales_total   R-squared (uncentered):                   0.363\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.363\n",
      "Method:                 Least Squares   F-statistic:                              3042.\n",
      "Date:                Sat, 22 Feb 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        14:19:01   Log-Likelihood:                     -2.0411e+06\n",
      "No. Observations:               90612   AIC:                                  4.082e+06\n",
      "Df Residuals:                   90595   BIC:                                  4.082e+06\n",
      "Df Model:                          17                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          2.162e+08   4.96e+06     43.570      0.000    2.07e+08    2.26e+08\n",
      "x2          3.348e+08   5.01e+06     66.867      0.000    3.25e+08    3.45e+08\n",
      "x3          2.085e+07   2.14e+06      9.725      0.000    1.67e+07    2.51e+07\n",
      "x4          1.742e+08   1.75e+07      9.937      0.000     1.4e+08    2.09e+08\n",
      "x5          -6.35e+06   1.81e+07     -0.350      0.726   -4.19e+07    2.92e+07\n",
      "x6          3.417e+07   6.35e+06      5.386      0.000    2.17e+07    4.66e+07\n",
      "x7          1.007e+08   5.67e+06     17.759      0.000    8.96e+07    1.12e+08\n",
      "x8          5.626e+07   8.21e+06      6.856      0.000    4.02e+07    7.23e+07\n",
      "x9         -1.154e+08    7.1e+06    -16.238      0.000   -1.29e+08   -1.01e+08\n",
      "x10         -1.28e+08   7.58e+06    -16.881      0.000   -1.43e+08   -1.13e+08\n",
      "x11         1.422e+07   7.66e+06      1.857      0.063   -7.87e+05    2.92e+07\n",
      "x12          3.43e+08   6.49e+06     52.815      0.000     3.3e+08    3.56e+08\n",
      "x13         3.467e+08   8.71e+06     39.779      0.000     3.3e+08    3.64e+08\n",
      "x14          2.38e+08   9.72e+06     24.496      0.000    2.19e+08    2.57e+08\n",
      "x15         3.189e+08   8.55e+06     37.284      0.000    3.02e+08    3.36e+08\n",
      "x16         5.675e+08   1.13e+07     50.205      0.000    5.45e+08     5.9e+08\n",
      "x17         4.278e+08   1.39e+07     30.792      0.000    4.01e+08    4.55e+08\n",
      "==============================================================================\n",
      "Omnibus:                   103377.250   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         30608518.291\n",
      "Skew:                           5.554   Prob(JB):                         0.00\n",
      "Kurtosis:                      92.352   Cond. No.                         13.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#OLS summary를 보기위해 \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.iloc[:,2:], y, test_size=0.2, random_state=50) \n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "Xs_train = rb.fit_transform(X_train)\n",
    "Xs_test = rb.transform(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, Xs_train)\n",
    "result = model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀분석 (1010개 상권코드) + 업종코드 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2) \n",
    "\n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "Xs_train = rb.fit_transform(X_train)\n",
    "Xs_test = rb.transform(X_test)\n",
    "\n",
    "# 회귀분석\n",
    "regressor = LinearRegression()\n",
    "model = regressor.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34216988281478933\n",
      "0.33083343286213285\n",
      "==================================================\n",
      "==================================================\n",
      "R-Square:  0.33083343286213285\n",
      "Mean Absolute Error: 734530688.4682939\n",
      "Mean Squared Error: 2.033105330730663e+18\n",
      "Root Mean Squared Error: 1425870025.8896892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 정확도 결과값\n",
    "print(model.score(Xs_train, y_train))\n",
    "print(model.score(Xs_test, y_test))\n",
    "\n",
    "print('='*50)\n",
    "print('='*50)\n",
    "# 오차 결과값\n",
    "from sklearn import metrics\n",
    "y_pred = model.predict(Xs_test)\n",
    "print('R-Square: ',r2_score(y_test , y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            sales_total   R-squared:                       0.343\n",
      "Model:                            OLS   Adj. R-squared:                  0.336\n",
      "Method:                 Least Squares   F-statistic:                     45.66\n",
      "Date:                Sat, 22 Feb 2020   Prob (F-statistic):               0.00\n",
      "Time:                        11:35:33   Log-Likelihood:            -2.0350e+06\n",
      "No. Observations:               90612   AIC:                         4.072e+06\n",
      "Df Residuals:                   89586   BIC:                         4.082e+06\n",
      "Df Model:                        1025                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          3.535e+07   1.49e+08      0.237      0.813   -2.57e+08    3.28e+08\n",
      "x2         -1.376e+08   3.83e+08     -0.359      0.719   -8.88e+08    6.13e+08\n",
      "x3           4.09e+08   1.43e+08      2.867      0.004    1.29e+08    6.89e+08\n",
      "x4          2.166e+08   1.56e+08      1.388      0.165   -8.92e+07    5.22e+08\n",
      "x5         -1.486e+08   1.84e+08     -0.810      0.418   -5.08e+08    2.11e+08\n",
      "x6          2.578e+08   1.81e+08      1.421      0.155   -9.78e+07    6.13e+08\n",
      "x7          7.483e+08   1.99e+08      3.762      0.000    3.58e+08    1.14e+09\n",
      "x8          6.412e+08    2.4e+08      2.675      0.007    1.71e+08    1.11e+09\n",
      "x9          2.726e+08   2.11e+08      1.293      0.196   -1.41e+08    6.86e+08\n",
      "x10        -3.385e+08   1.39e+08     -2.443      0.015    -6.1e+08   -6.69e+07\n",
      "x11         3.833e+08   1.39e+08      2.756      0.006    1.11e+08    6.56e+08\n",
      "x12         -7.57e+06   1.74e+08     -0.043      0.965   -3.49e+08    3.34e+08\n",
      "x13         2.527e+08   1.73e+08      1.465      0.143   -8.54e+07    5.91e+08\n",
      "x14         2.749e+08   2.18e+08      1.262      0.207   -1.52e+08    7.02e+08\n",
      "x15         4.642e+08   1.39e+08      3.328      0.001    1.91e+08    7.38e+08\n",
      "x16         2.572e+08    1.3e+08      1.977      0.048    2.16e+06    5.12e+08\n",
      "x17        -2.323e+08   4.18e+08     -0.556      0.578   -1.05e+09    5.87e+08\n",
      "x18         4.001e+08   3.84e+08      1.043      0.297   -3.52e+08    1.15e+09\n",
      "x19        -7.125e+07   1.38e+08     -0.515      0.607   -3.43e+08       2e+08\n",
      "x20         3.668e+08   1.56e+08      2.347      0.019    6.05e+07    6.73e+08\n",
      "x21        -1.996e+08   1.67e+08     -1.194      0.233   -5.27e+08    1.28e+08\n",
      "x22         2.773e+08   1.43e+08      1.937      0.053   -3.31e+06    5.58e+08\n",
      "x23        -1.423e+08   2.14e+08     -0.663      0.507   -5.63e+08    2.78e+08\n",
      "x24         -2.15e+08    2.2e+08     -0.978      0.328   -6.46e+08    2.16e+08\n",
      "x25        -3.631e+08   2.65e+08     -1.369      0.171   -8.83e+08    1.57e+08\n",
      "x26        -1.477e+08   2.15e+08     -0.687      0.492   -5.69e+08    2.73e+08\n",
      "x27        -2.039e+08   2.07e+08     -0.986      0.324   -6.09e+08    2.01e+08\n",
      "x28        -2.136e+08   1.29e+08     -1.659      0.097   -4.66e+08    3.88e+07\n",
      "x29         8.902e+08   3.28e+08      2.715      0.007    2.48e+08    1.53e+09\n",
      "x30        -1.955e+08   1.53e+08     -1.276      0.202   -4.96e+08    1.05e+08\n",
      "x31        -4.097e+08   1.47e+08     -2.779      0.005   -6.99e+08   -1.21e+08\n",
      "x32        -3.818e+08   1.24e+08     -3.073      0.002   -6.25e+08   -1.38e+08\n",
      "x33        -4.031e+08   1.49e+08     -2.710      0.007   -6.95e+08   -1.12e+08\n",
      "x34        -1.873e+08   1.26e+08     -1.491      0.136   -4.34e+08     5.9e+07\n",
      "x35        -1.003e+08   1.59e+08     -0.632      0.527   -4.11e+08    2.11e+08\n",
      "x36        -1.244e+08   1.74e+08     -0.715      0.474   -4.65e+08    2.16e+08\n",
      "x37        -4.083e+08   2.61e+08     -1.565      0.118    -9.2e+08    1.03e+08\n",
      "x38         2.903e+08   3.26e+08      0.891      0.373   -3.49e+08    9.29e+08\n",
      "x39         9.554e+08   1.42e+08      6.736      0.000    6.77e+08    1.23e+09\n",
      "x40        -1.236e+08   1.84e+08     -0.670      0.503   -4.85e+08    2.38e+08\n",
      "x41        -6.646e+07   1.32e+08     -0.504      0.614   -3.25e+08    1.92e+08\n",
      "x42        -6.798e+08   1.78e+08     -3.820      0.000   -1.03e+09   -3.31e+08\n",
      "x43        -1.223e+09   1.92e+08     -6.360      0.000    -1.6e+09   -8.46e+08\n",
      "x44        -5.409e+08   1.96e+08     -2.757      0.006   -9.25e+08   -1.56e+08\n",
      "x45        -1.634e+08   1.48e+08     -1.106      0.269   -4.53e+08    1.26e+08\n",
      "x46         3.896e+07   1.35e+08      0.288      0.774   -2.26e+08    3.04e+08\n",
      "x47        -6.894e+08   1.67e+08     -4.123      0.000   -1.02e+09   -3.62e+08\n",
      "x48        -6.696e+08   1.45e+08     -4.621      0.000   -9.54e+08   -3.86e+08\n",
      "x49        -6.482e+08   2.75e+08     -2.356      0.018   -1.19e+09   -1.09e+08\n",
      "x50        -6.025e+08   1.63e+08     -3.703      0.000   -9.21e+08   -2.84e+08\n",
      "x51         2.377e+08   1.82e+08      1.308      0.191   -1.18e+08    5.94e+08\n",
      "x52         3.637e+08   1.64e+08      2.212      0.027    4.14e+07    6.86e+08\n",
      "x53         8.711e+07   1.55e+08      0.561      0.575   -2.17e+08    3.91e+08\n",
      "x54         3.805e+08   1.51e+08      2.527      0.011    8.54e+07    6.76e+08\n",
      "x55         3.195e+08   1.51e+08      2.120      0.034    2.41e+07    6.15e+08\n",
      "x56        -1.981e+08   1.35e+08     -1.464      0.143   -4.63e+08     6.7e+07\n",
      "x57        -7.228e+08   1.84e+08     -3.929      0.000   -1.08e+09   -3.62e+08\n",
      "x58        -8.152e+08    2.4e+08     -3.396      0.001   -1.29e+09   -3.45e+08\n",
      "x59        -3.986e+08   1.67e+08     -2.391      0.017   -7.25e+08   -7.18e+07\n",
      "x60         4.782e+08   1.39e+08      3.429      0.001    2.05e+08    7.51e+08\n",
      "x61        -8.731e+08   1.61e+08     -5.419      0.000   -1.19e+09   -5.57e+08\n",
      "x62         4.345e+08   1.98e+08      2.198      0.028     4.7e+07    8.22e+08\n",
      "x63        -5.312e+08   1.64e+08     -3.241      0.001   -8.53e+08    -2.1e+08\n",
      "x64        -5.243e+08   1.49e+08     -3.513      0.000   -8.17e+08   -2.32e+08\n",
      "x65        -7.228e+08   2.23e+08     -3.246      0.001   -1.16e+09   -2.86e+08\n",
      "x66        -4.628e+08   1.42e+08     -3.256      0.001   -7.41e+08   -1.84e+08\n",
      "x67        -4.572e+08   1.43e+08     -3.195      0.001   -7.38e+08   -1.77e+08\n",
      "x68        -3.267e+08   1.63e+08     -2.003      0.045   -6.46e+08      -7e+06\n",
      "x69         1.666e+09   1.55e+08     10.726      0.000    1.36e+09    1.97e+09\n",
      "x70        -6.878e+06   1.59e+08     -0.043      0.966   -3.19e+08    3.05e+08\n",
      "x71        -3.392e+08   1.34e+08     -2.536      0.011   -6.01e+08    -7.7e+07\n",
      "x72         4.152e+08    1.4e+08      2.967      0.003    1.41e+08     6.9e+08\n",
      "x73         2.144e+08   1.75e+08      1.228      0.219   -1.28e+08    5.57e+08\n",
      "x74        -7.185e+07   1.52e+08     -0.473      0.636    -3.7e+08    2.26e+08\n",
      "x75         7.501e+08   2.19e+08      3.423      0.001    3.21e+08    1.18e+09\n",
      "x76        -5.175e+08   1.38e+08     -3.747      0.000   -7.88e+08   -2.47e+08\n",
      "x77        -8.746e+08   1.76e+08     -4.965      0.000   -1.22e+09   -5.29e+08\n",
      "x78        -5.638e+08   1.28e+08     -4.406      0.000   -8.15e+08   -3.13e+08\n",
      "x79         -1.24e+09   1.75e+08     -7.073      0.000   -1.58e+09   -8.96e+08\n",
      "x80        -8.496e+08   1.63e+08     -5.207      0.000   -1.17e+09    -5.3e+08\n",
      "x81        -4.981e+08   1.68e+08     -2.957      0.003   -8.28e+08   -1.68e+08\n",
      "x82         3.129e+08   3.84e+08      0.814      0.415    -4.4e+08    1.07e+09\n",
      "x83        -4.662e+08   3.28e+08     -1.421      0.155   -1.11e+09    1.77e+08\n",
      "x84        -6.219e+04    1.3e+08     -0.000      1.000   -2.56e+08    2.56e+08\n",
      "x85         3.391e+07   1.34e+08      0.253      0.800   -2.29e+08    2.97e+08\n",
      "x86         1.717e+08   1.44e+08      1.194      0.233    -1.1e+08    4.54e+08\n",
      "x87        -1.361e+09   1.79e+08     -7.609      0.000   -1.71e+09   -1.01e+09\n",
      "x88        -6.443e+08   2.29e+08     -2.812      0.005   -1.09e+09   -1.95e+08\n",
      "x89        -1.335e+08   1.52e+08     -0.876      0.381   -4.32e+08    1.65e+08\n",
      "x90        -3.557e+08   1.22e+08     -2.917      0.004   -5.95e+08   -1.17e+08\n",
      "x91         1.145e+08   3.69e+08      0.310      0.757    -6.1e+08    8.38e+08\n",
      "x92        -2.435e+07   1.58e+08     -0.155      0.877   -3.33e+08    2.84e+08\n",
      "x93         7.836e+08   1.46e+08      5.351      0.000    4.97e+08    1.07e+09\n",
      "x94        -2.085e+08   1.97e+08     -1.056      0.291   -5.95e+08    1.78e+08\n",
      "x95        -1.765e+08   3.17e+08     -0.556      0.578   -7.99e+08    4.46e+08\n",
      "x96         -5.44e+08   2.15e+08     -2.526      0.012   -9.66e+08   -1.22e+08\n",
      "x97        -3.294e+08    1.3e+08     -2.533      0.011   -5.84e+08   -7.46e+07\n",
      "x98         3.497e+08   1.37e+08      2.545      0.011    8.04e+07    6.19e+08\n",
      "x99         1.202e+08   1.59e+08      0.754      0.451   -1.92e+08    4.33e+08\n",
      "x100       -2.812e+08   1.64e+08     -1.710      0.087   -6.04e+08    4.12e+07\n",
      "x101        9.324e+07   1.55e+08      0.600      0.548   -2.11e+08    3.98e+08\n",
      "x102       -1.838e+08   2.23e+08     -0.822      0.411   -6.22e+08    2.54e+08\n",
      "x103        3.986e+08   1.15e+08      3.467      0.001    1.73e+08    6.24e+08\n",
      "x104       -1.801e+08   1.59e+08     -1.134      0.257   -4.92e+08    1.31e+08\n",
      "x105       -3.679e+08   1.25e+08     -2.951      0.003   -6.12e+08   -1.24e+08\n",
      "x106       -3.942e+08   1.43e+08     -2.753      0.006   -6.75e+08   -1.14e+08\n",
      "x107       -9.585e+07    1.8e+08     -0.532      0.595   -4.49e+08    2.57e+08\n",
      "x108       -1.756e+08   1.51e+08     -1.163      0.245   -4.72e+08     1.2e+08\n",
      "x109       -8.857e+07   1.34e+08     -0.661      0.509   -3.51e+08    1.74e+08\n",
      "x110        1.205e+08   1.57e+08      0.768      0.442   -1.87e+08    4.28e+08\n",
      "x111       -2.883e+08   1.29e+08     -2.232      0.026   -5.41e+08   -3.52e+07\n",
      "x112       -4.075e+08   1.77e+08     -2.304      0.021   -7.54e+08   -6.09e+07\n",
      "x113         4.75e+08   1.58e+08      3.006      0.003    1.65e+08    7.85e+08\n",
      "x114       -2.591e+08    1.6e+08     -1.621      0.105   -5.72e+08    5.42e+07\n",
      "x115       -5.397e+07   1.49e+08     -0.363      0.717   -3.46e+08    2.38e+08\n",
      "x116       -2.109e+08   1.45e+08     -1.459      0.145   -4.94e+08    7.25e+07\n",
      "x117       -3.091e+08   1.25e+08     -2.481      0.013   -5.53e+08   -6.49e+07\n",
      "x118       -2.505e+08   1.39e+08     -1.796      0.072   -5.24e+08    2.28e+07\n",
      "x119       -4.573e+07    1.3e+08     -0.353      0.724      -3e+08    2.08e+08\n",
      "x120        5.833e+08   1.24e+08      4.709      0.000    3.41e+08    8.26e+08\n",
      "x121        7.479e+07   1.71e+08      0.438      0.662    -2.6e+08     4.1e+08\n",
      "x122       -2.536e+08   1.19e+08     -2.134      0.033   -4.86e+08   -2.07e+07\n",
      "x123       -1.343e+08   1.52e+08     -0.884      0.377   -4.32e+08    1.63e+08\n",
      "x124       -9.351e+08   2.87e+08     -3.253      0.001    -1.5e+09   -3.72e+08\n",
      "x125       -9.918e+08   2.25e+08     -4.406      0.000   -1.43e+09   -5.51e+08\n",
      "x126        3.742e+08   1.39e+08      2.700      0.007    1.03e+08    6.46e+08\n",
      "x127        3.874e+08   1.59e+08      2.431      0.015    7.51e+07       7e+08\n",
      "x128        9.502e+08   1.31e+08      7.233      0.000    6.93e+08    1.21e+09\n",
      "x129        2.008e+08   1.67e+08      1.206      0.228   -1.26e+08    5.27e+08\n",
      "x130       -8.949e+07   1.42e+08     -0.628      0.530   -3.69e+08     1.9e+08\n",
      "x131       -6.316e+08   1.57e+08     -4.028      0.000   -9.39e+08   -3.24e+08\n",
      "x132        5.343e+08   1.31e+08      4.085      0.000    2.78e+08    7.91e+08\n",
      "x133        6.383e+08   1.23e+08      5.190      0.000    3.97e+08    8.79e+08\n",
      "x134       -7.765e+07   1.94e+08     -0.401      0.688   -4.57e+08    3.02e+08\n",
      "x135        5.756e+07   1.33e+08      0.434      0.664   -2.02e+08    3.18e+08\n",
      "x136        1.826e+08   1.26e+08      1.447      0.148   -6.47e+07     4.3e+08\n",
      "x137        2.138e+08   1.47e+08      1.454      0.146   -7.44e+07    5.02e+08\n",
      "x138        6.092e+08   1.33e+08      4.572      0.000    3.48e+08     8.7e+08\n",
      "x139       -7.442e+08   1.34e+08     -5.543      0.000   -1.01e+09   -4.81e+08\n",
      "x140       -5.501e+08   1.53e+08     -3.586      0.000   -8.51e+08   -2.49e+08\n",
      "x141        2.613e+08   1.34e+08      1.952      0.051   -1.11e+06    5.24e+08\n",
      "x142         1.13e+08   1.93e+08      0.585      0.559   -2.66e+08    4.92e+08\n",
      "x143       -4.178e+08   1.45e+08     -2.875      0.004   -7.03e+08   -1.33e+08\n",
      "x144       -1.632e+08   1.47e+08     -1.111      0.267   -4.51e+08    1.25e+08\n",
      "x145        -2.37e+07    1.4e+08     -0.170      0.865   -2.97e+08     2.5e+08\n",
      "x146       -1.086e+08   1.56e+08     -0.697      0.486   -4.14e+08    1.97e+08\n",
      "x147       -1.435e+08   1.17e+08     -1.228      0.219   -3.73e+08    8.55e+07\n",
      "x148       -2.864e+08   1.45e+08     -1.977      0.048    -5.7e+08   -2.44e+06\n",
      "x149       -1.364e+08   1.59e+08     -0.855      0.392   -4.49e+08    1.76e+08\n",
      "x150       -7.117e+07   1.55e+08     -0.458      0.647   -3.76e+08    2.34e+08\n",
      "x151        3.412e+08   1.88e+08      1.812      0.070   -2.79e+07     7.1e+08\n",
      "x152        9.481e+07   1.31e+08      0.726      0.468   -1.61e+08    3.51e+08\n",
      "x153        7.702e+07   1.23e+08      0.624      0.533   -1.65e+08    3.19e+08\n",
      "x154       -7.581e+08   1.79e+08     -4.246      0.000   -1.11e+09   -4.08e+08\n",
      "x155        3.507e+08   1.32e+08      2.664      0.008    9.27e+07    6.09e+08\n",
      "x156        1.453e+08   1.95e+08      0.747      0.455   -2.36e+08    5.27e+08\n",
      "x157       -1.863e+08   1.37e+08     -1.359      0.174   -4.55e+08    8.24e+07\n",
      "x158        6.117e+08   1.47e+08      4.148      0.000    3.23e+08    9.01e+08\n",
      "x159        3.048e+08   1.39e+08      2.191      0.028    3.21e+07    5.77e+08\n",
      "x160        9.471e+08   1.18e+08      7.999      0.000    7.15e+08    1.18e+09\n",
      "x161        1.653e+08   1.29e+08      1.286      0.198   -8.66e+07    4.17e+08\n",
      "x162        2.059e+08   1.63e+08      1.260      0.208   -1.14e+08    5.26e+08\n",
      "x163        -6.68e+08   1.52e+08     -4.397      0.000   -9.66e+08    -3.7e+08\n",
      "x164       -6.253e+07   1.24e+08     -0.505      0.613   -3.05e+08     1.8e+08\n",
      "x165        7.931e+08   1.32e+08      6.018      0.000    5.35e+08    1.05e+09\n",
      "x166         5.67e+08   1.23e+08      4.612      0.000    3.26e+08    8.08e+08\n",
      "x167        5.731e+08   1.69e+08      3.398      0.001    2.43e+08    9.04e+08\n",
      "x168       -2.183e+08    3.7e+08     -0.590      0.555   -9.44e+08    5.07e+08\n",
      "x169        4.587e+08   1.95e+08      2.352      0.019    7.65e+07    8.41e+08\n",
      "x170       -1.126e+08   1.79e+08     -0.629      0.529   -4.63e+08    2.38e+08\n",
      "x171        2.879e+08   1.51e+08      1.908      0.056   -7.78e+06    5.84e+08\n",
      "x172        2.099e+08    1.4e+08      1.496      0.135   -6.52e+07    4.85e+08\n",
      "x173        -3.73e+07   3.01e+08     -0.124      0.901   -6.27e+08    5.53e+08\n",
      "x174       -1.046e+08    1.5e+08     -0.699      0.484   -3.98e+08    1.89e+08\n",
      "x175        2.048e+08   1.46e+08      1.407      0.159   -8.05e+07     4.9e+08\n",
      "x176        5.029e+08   1.23e+08      4.095      0.000    2.62e+08    7.44e+08\n",
      "x177         1.06e+08   1.44e+08      0.735      0.462   -1.77e+08    3.89e+08\n",
      "x178        2.049e+08   1.88e+08      1.091      0.275   -1.63e+08    5.73e+08\n",
      "x179        8.169e+08   1.32e+08      6.180      0.000    5.58e+08    1.08e+09\n",
      "x180        1.295e+08   1.46e+08      0.887      0.375   -1.57e+08    4.16e+08\n",
      "x181       -2.642e+08   2.22e+08     -1.190      0.234      -7e+08    1.71e+08\n",
      "x182       -2.046e+08   1.81e+08     -1.130      0.258   -5.59e+08     1.5e+08\n",
      "x183        6.155e+07   1.23e+08      0.500      0.617    -1.8e+08    3.03e+08\n",
      "x184        3.985e+07   1.26e+08      0.316      0.752   -2.08e+08    2.87e+08\n",
      "x185        2.809e+08   3.17e+08      0.886      0.376    -3.4e+08    9.02e+08\n",
      "x186       -1.719e+08   3.09e+08     -0.557      0.578   -7.77e+08    4.33e+08\n",
      "x187       -8.684e+07   1.52e+08     -0.571      0.568   -3.85e+08    2.11e+08\n",
      "x188        2.286e+07   1.38e+08      0.166      0.869   -2.48e+08    2.94e+08\n",
      "x189       -3.483e+08    1.3e+08     -2.686      0.007   -6.02e+08   -9.42e+07\n",
      "x190        8.427e+07   2.35e+08      0.358      0.720   -3.77e+08    5.46e+08\n",
      "x191       -9.525e+08   2.19e+08     -4.356      0.000   -1.38e+09   -5.24e+08\n",
      "x192       -1.895e+08   1.23e+08     -1.543      0.123    -4.3e+08    5.12e+07\n",
      "x193        8.907e+07   2.19e+08      0.407      0.684    -3.4e+08    5.18e+08\n",
      "x194         8.18e+07    1.5e+08      0.545      0.586   -2.12e+08    3.76e+08\n",
      "x195        2.285e+08   1.32e+08      1.729      0.084   -3.06e+07    4.88e+08\n",
      "x196         6.23e+08   1.77e+08      3.521      0.000    2.76e+08     9.7e+08\n",
      "x197        2.272e+08   1.24e+08      1.830      0.067   -1.61e+07    4.71e+08\n",
      "x198        1.267e+08   1.68e+08      0.756      0.450   -2.02e+08    4.55e+08\n",
      "x199        1.214e+08   1.48e+08      0.819      0.413   -1.69e+08    4.12e+08\n",
      "x200       -1.463e+08   1.22e+08     -1.195      0.232   -3.86e+08    9.37e+07\n",
      "x201        1.656e+08   1.75e+08      0.948      0.343   -1.77e+08    5.08e+08\n",
      "x202       -2.775e+08   1.62e+08     -1.717      0.086   -5.94e+08    3.92e+07\n",
      "x203        7.587e+07   1.34e+08      0.565      0.572   -1.87e+08    3.39e+08\n",
      "x204       -9.531e+07   1.49e+08     -0.642      0.521   -3.86e+08    1.96e+08\n",
      "x205       -2.842e+08   2.41e+08     -1.180      0.238   -7.56e+08    1.88e+08\n",
      "x206       -2.836e+08   1.51e+08     -1.878      0.060    -5.8e+08    1.24e+07\n",
      "x207        2.773e+08   1.67e+08      1.662      0.096   -4.96e+07    6.04e+08\n",
      "x208       -4.502e+07   3.83e+08     -0.118      0.906   -7.95e+08    7.05e+08\n",
      "x209       -1.531e+08   1.65e+08     -0.930      0.352   -4.76e+08     1.7e+08\n",
      "x210        1.601e+08   4.88e+08      0.328      0.743   -7.97e+08    1.12e+09\n",
      "x211       -2.874e+08   3.26e+08     -0.882      0.378   -9.26e+08    3.52e+08\n",
      "x212        6.587e+07   2.01e+08      0.328      0.743   -3.28e+08    4.59e+08\n",
      "x213        2.736e+08    1.4e+08      1.955      0.051   -6.86e+05    5.48e+08\n",
      "x214        1.336e+08   1.42e+08      0.943      0.346   -1.44e+08    4.11e+08\n",
      "x215        3.033e+08   1.52e+08      1.989      0.047    4.46e+06    6.02e+08\n",
      "x216        6.004e+08   1.36e+08      4.418      0.000    3.34e+08    8.67e+08\n",
      "x217       -1.906e+08   1.68e+08     -1.135      0.256    -5.2e+08    1.39e+08\n",
      "x218       -2.586e+08   2.19e+08     -1.178      0.239   -6.89e+08    1.72e+08\n",
      "x219        1.204e+08   1.18e+08      1.020      0.308   -1.11e+08    3.52e+08\n",
      "x220       -3.747e+07   1.31e+08     -0.285      0.776   -2.95e+08     2.2e+08\n",
      "x221        3.848e+08   1.29e+08      2.974      0.003    1.31e+08    6.38e+08\n",
      "x222        3.613e+07    1.7e+08      0.212      0.832   -2.98e+08     3.7e+08\n",
      "x223        3.902e+08   1.64e+08      2.379      0.017    6.87e+07    7.12e+08\n",
      "x224        -1.48e+08   1.68e+08     -0.881      0.379   -4.78e+08    1.81e+08\n",
      "x225        4.251e+08   1.16e+08      3.673      0.000    1.98e+08    6.52e+08\n",
      "x226        1.005e+08   1.48e+08      0.679      0.497    -1.9e+08    3.91e+08\n",
      "x227        1.141e+08    1.8e+08      0.633      0.527   -2.39e+08    4.67e+08\n",
      "x228        2.155e+08   1.23e+08      1.753      0.080   -2.54e+07    4.56e+08\n",
      "x229       -5.812e+07   1.23e+08     -0.472      0.637   -2.99e+08    1.83e+08\n",
      "x230          3.7e+08   1.26e+08      2.928      0.003    1.22e+08    6.18e+08\n",
      "x231       -1.295e+08   1.38e+08     -0.942      0.346   -3.99e+08     1.4e+08\n",
      "x232        1.329e+08   1.19e+08      1.113      0.266   -1.01e+08    3.67e+08\n",
      "x233        1.041e+08   1.82e+08      0.571      0.568   -2.53e+08    4.61e+08\n",
      "x234        1.645e+08    1.3e+08      1.269      0.204   -8.96e+07    4.19e+08\n",
      "x235       -1.833e+08   1.73e+08     -1.062      0.288   -5.21e+08    1.55e+08\n",
      "x236        7.734e+08   1.18e+08      6.538      0.000    5.42e+08    1.01e+09\n",
      "x237       -3.418e+08   1.46e+08     -2.337      0.019   -6.28e+08   -5.52e+07\n",
      "x238        5.025e+08   1.26e+08      3.998      0.000    2.56e+08    7.49e+08\n",
      "x239        7.233e+07   1.62e+08      0.448      0.654   -2.44e+08    3.89e+08\n",
      "x240        3.203e+07   1.67e+08      0.191      0.848   -2.96e+08     3.6e+08\n",
      "x241       -2.223e+08   1.52e+08     -1.466      0.143    -5.2e+08    7.49e+07\n",
      "x242        5.005e+08   1.43e+08      3.509      0.000    2.21e+08     7.8e+08\n",
      "x243        3.074e+08   1.31e+08      2.342      0.019    5.01e+07    5.65e+08\n",
      "x244        1.831e+08   1.31e+08      1.401      0.161    -7.3e+07    4.39e+08\n",
      "x245        1.046e+08   1.66e+08      0.629      0.529   -2.22e+08    4.31e+08\n",
      "x246        5.371e+07   1.28e+08      0.420      0.675   -1.97e+08    3.04e+08\n",
      "x247       -2.908e+08    1.6e+08     -1.814      0.070   -6.05e+08    2.34e+07\n",
      "x248         2.15e+08   1.41e+08      1.528      0.127   -6.08e+07    4.91e+08\n",
      "x249        1.399e+08   2.28e+08      0.613      0.540   -3.08e+08    5.87e+08\n",
      "x250        1.147e+08   1.64e+08      0.700      0.484   -2.07e+08    4.36e+08\n",
      "x251         2.73e+08   1.15e+08      2.381      0.017    4.83e+07    4.98e+08\n",
      "x252        1.893e+08   1.66e+08      1.140      0.254   -1.36e+08    5.15e+08\n",
      "x253        3.717e+08   1.24e+08      3.008      0.003    1.29e+08    6.14e+08\n",
      "x254        9.425e+06   1.53e+08      0.062      0.951    -2.9e+08    3.09e+08\n",
      "x255        5.154e+08    1.5e+08      3.443      0.001    2.22e+08    8.09e+08\n",
      "x256        2.653e+08   1.57e+08      1.694      0.090   -4.17e+07    5.72e+08\n",
      "x257        1.637e+08   1.27e+08      1.291      0.197   -8.49e+07    4.12e+08\n",
      "x258        1.802e+08   1.52e+08      1.183      0.237   -1.18e+08    4.79e+08\n",
      "x259        1.948e+08   1.32e+08      1.478      0.139   -6.35e+07    4.53e+08\n",
      "x260       -4.893e+08   1.72e+08     -2.852      0.004   -8.25e+08   -1.53e+08\n",
      "x261        9.685e+07   3.11e+08      0.311      0.756   -5.13e+08    7.07e+08\n",
      "x262        2.073e+08   1.31e+08      1.582      0.114   -4.96e+07    4.64e+08\n",
      "x263       -1.258e+08   1.32e+08     -0.952      0.341   -3.85e+08    1.33e+08\n",
      "x264        3.401e+08   1.64e+08      2.077      0.038    1.92e+07    6.61e+08\n",
      "x265       -1.321e+08   1.61e+08     -0.818      0.413   -4.48e+08    1.84e+08\n",
      "x266        6.707e+07   2.06e+08      0.326      0.744   -3.36e+08     4.7e+08\n",
      "x267       -5.798e+07   1.59e+08     -0.365      0.715   -3.69e+08    2.54e+08\n",
      "x268       -8.789e+07   1.51e+08     -0.583      0.560   -3.84e+08    2.08e+08\n",
      "x269        1.306e+08   1.32e+08      0.989      0.323   -1.28e+08    3.89e+08\n",
      "x270        1.718e+08   2.95e+08      0.583      0.560   -4.06e+08     7.5e+08\n",
      "x271        4.252e+08   3.58e+08      1.189      0.235   -2.76e+08    1.13e+09\n",
      "x272        1.374e+08   1.32e+08      1.041      0.298   -1.21e+08    3.96e+08\n",
      "x273       -5.546e+07   1.42e+08     -0.389      0.697   -3.35e+08    2.24e+08\n",
      "x274        3.991e+08   6.17e+08      0.646      0.518   -8.11e+08    1.61e+09\n",
      "x275       -1.961e+08   1.31e+08     -1.497      0.134   -4.53e+08    6.07e+07\n",
      "x276       -1.195e+08   1.58e+08     -0.758      0.448   -4.28e+08    1.89e+08\n",
      "x277       -2.339e+08   1.18e+08     -1.980      0.048   -4.66e+08   -2.33e+06\n",
      "x278       -2.741e+08   2.67e+08     -1.028      0.304   -7.96e+08    2.48e+08\n",
      "x279       -5.405e+08   1.94e+08     -2.786      0.005   -9.21e+08    -1.6e+08\n",
      "x280        -1.22e+08   1.44e+08     -0.844      0.398   -4.05e+08    1.61e+08\n",
      "x281          5.1e+08   1.45e+08      3.529      0.000    2.27e+08    7.93e+08\n",
      "x282        2.347e+08   2.23e+08      1.051      0.293   -2.03e+08    6.72e+08\n",
      "x283       -2.845e+08   1.32e+08     -2.154      0.031   -5.43e+08   -2.56e+07\n",
      "x284        4.519e+08   2.03e+08      2.229      0.026    5.46e+07    8.49e+08\n",
      "x285       -1.318e+08   1.37e+08     -0.962      0.336      -4e+08    1.37e+08\n",
      "x286       -2.368e+08    1.9e+08     -1.243      0.214    -6.1e+08    1.36e+08\n",
      "x287        1.194e+08    1.1e+08      1.088      0.277   -9.58e+07    3.35e+08\n",
      "x288       -3.831e+08   1.68e+08     -2.281      0.023   -7.12e+08   -5.39e+07\n",
      "x289       -4.678e+08   1.37e+08     -3.420      0.001   -7.36e+08      -2e+08\n",
      "x290        7.577e+08   1.58e+08      4.807      0.000    4.49e+08    1.07e+09\n",
      "x291        6.935e+08   1.45e+08      4.798      0.000     4.1e+08    9.77e+08\n",
      "x292       -5.323e+05   1.52e+08     -0.004      0.997   -2.99e+08    2.98e+08\n",
      "x293       -1.293e+08   1.52e+08     -0.852      0.394   -4.27e+08    1.68e+08\n",
      "x294       -1.013e+08   1.27e+08     -0.796      0.426   -3.51e+08    1.48e+08\n",
      "x295        5.041e+07   1.77e+08      0.285      0.776   -2.96e+08    3.97e+08\n",
      "x296       -1.353e+08   3.08e+08     -0.439      0.661    -7.4e+08    4.69e+08\n",
      "x297        2.488e+07   1.59e+08      0.156      0.876   -2.87e+08    3.37e+08\n",
      "x298        4.834e+08   1.56e+08      3.089      0.002    1.77e+08     7.9e+08\n",
      "x299       -1.371e+08   1.59e+08     -0.863      0.388   -4.48e+08    1.74e+08\n",
      "x300       -6.071e+07   1.28e+08     -0.475      0.635   -3.11e+08     1.9e+08\n",
      "x301        5.555e+07    1.3e+08      0.428      0.669   -1.99e+08     3.1e+08\n",
      "x302       -3.553e+08   1.58e+08     -2.248      0.025   -6.65e+08   -4.55e+07\n",
      "x303        3.745e+08   1.61e+08      2.327      0.020    5.91e+07     6.9e+08\n",
      "x304       -2.015e+07   1.34e+08     -0.150      0.880   -2.83e+08    2.42e+08\n",
      "x305        6.156e+08   1.56e+08      3.952      0.000     3.1e+08    9.21e+08\n",
      "x306       -4.471e+08    2.4e+08     -1.860      0.063   -9.18e+08     2.4e+07\n",
      "x307        4.171e+08   1.38e+08      3.025      0.002    1.47e+08    6.87e+08\n",
      "x308        1.479e+08   1.24e+08      1.195      0.232   -9.47e+07    3.91e+08\n",
      "x309        -2.22e+08   1.46e+08     -1.525      0.127   -5.07e+08    6.33e+07\n",
      "x310       -1.268e+08   1.62e+08     -0.783      0.434   -4.44e+08    1.91e+08\n",
      "x311       -3.588e+08   1.67e+08     -2.152      0.031   -6.86e+08    -3.2e+07\n",
      "x312       -1.217e+08   1.73e+08     -0.705      0.481    -4.6e+08    2.17e+08\n",
      "x313        1.809e+08   1.53e+08      1.179      0.238    -1.2e+08    4.82e+08\n",
      "x314         1.25e+08   1.36e+08      0.922      0.356   -1.41e+08    3.91e+08\n",
      "x315        2.554e+08   3.58e+08      0.713      0.476   -4.47e+08    9.58e+08\n",
      "x316       -1.379e+08    3.7e+08     -0.373      0.709   -8.62e+08    5.87e+08\n",
      "x317        3.588e+08    1.7e+08      2.113      0.035     2.6e+07    6.92e+08\n",
      "x318        4.047e+08   1.58e+08      2.566      0.010    9.55e+07    7.14e+08\n",
      "x319        -1.94e+08   2.37e+08     -0.818      0.413   -6.59e+08    2.71e+08\n",
      "x320        1.521e+08      2e+08      0.761      0.447    -2.4e+08    5.44e+08\n",
      "x321        5.145e+08    1.3e+08      3.949      0.000    2.59e+08     7.7e+08\n",
      "x322        5.059e+08   1.32e+08      3.837      0.000    2.47e+08    7.64e+08\n",
      "x323        1.787e+08   1.52e+08      1.172      0.241    -1.2e+08    4.78e+08\n",
      "x324        4.331e+08   1.87e+08      2.322      0.020    6.75e+07    7.99e+08\n",
      "x325        8.141e+07   2.23e+08      0.366      0.715   -3.55e+08    5.18e+08\n",
      "x326        3.761e+08   1.45e+08      2.599      0.009    9.25e+07     6.6e+08\n",
      "x327       -4.976e+08   1.97e+08     -2.525      0.012   -8.84e+08   -1.11e+08\n",
      "x328       -2.799e+08   1.72e+08     -1.625      0.104   -6.18e+08    5.78e+07\n",
      "x329       -5.454e+07   3.69e+08     -0.148      0.882   -7.77e+08    6.68e+08\n",
      "x330        -1.49e+07   1.38e+08     -0.108      0.914   -2.86e+08    2.56e+08\n",
      "x331        1.901e+08   2.89e+08      0.658      0.511   -3.76e+08    7.57e+08\n",
      "x332        1.322e+08   1.68e+08      0.786      0.432   -1.98e+08    4.62e+08\n",
      "x333        3.936e+08   1.77e+08      2.223      0.026    4.65e+07    7.41e+08\n",
      "x334       -6.182e+07   1.61e+08     -0.383      0.701   -3.78e+08    2.54e+08\n",
      "x335        1.616e+08   1.36e+08      1.189      0.234   -1.05e+08    4.28e+08\n",
      "x336        3.634e+08   1.25e+08      2.905      0.004    1.18e+08    6.09e+08\n",
      "x337       -8.611e+07   1.54e+08     -0.560      0.575   -3.87e+08    2.15e+08\n",
      "x338         2.69e+08   1.63e+08      1.655      0.098   -4.96e+07    5.88e+08\n",
      "x339        5.421e+06    2.3e+08      0.024      0.981   -4.46e+08    4.57e+08\n",
      "x340        1.443e+08   1.55e+08      0.928      0.353    -1.6e+08    4.49e+08\n",
      "x341        3.471e+08   1.48e+08      2.348      0.019    5.73e+07    6.37e+08\n",
      "x342        1.762e+08   1.83e+08      0.963      0.336   -1.82e+08    5.35e+08\n",
      "x343        5.452e+07   1.84e+08      0.297      0.766   -3.05e+08    4.14e+08\n",
      "x344        2.206e+08   1.65e+08      1.337      0.181   -1.03e+08    5.44e+08\n",
      "x345        9.381e+08   1.21e+08      7.765      0.000    7.01e+08    1.17e+09\n",
      "x346         3.15e+08   1.53e+08      2.056      0.040    1.48e+07    6.15e+08\n",
      "x347       -2.399e+08   3.02e+08     -0.795      0.427   -8.31e+08    3.51e+08\n",
      "x348        2.494e+07   1.21e+08      0.205      0.837   -2.13e+08    2.63e+08\n",
      "x349        4.534e+08   1.58e+08      2.865      0.004    1.43e+08    7.64e+08\n",
      "x350       -2.892e+08   1.46e+08     -1.982      0.048   -5.75e+08   -3.16e+06\n",
      "x351        6.086e+08   1.29e+08      4.703      0.000    3.55e+08    8.62e+08\n",
      "x352       -2.571e+08   1.45e+08     -1.773      0.076   -5.41e+08    2.71e+07\n",
      "x353        1.927e+08   1.68e+08      1.150      0.250   -1.36e+08    5.21e+08\n",
      "x354        2.872e+08    1.7e+08      1.692      0.091   -4.55e+07     6.2e+08\n",
      "x355        1.586e+08   1.48e+08      1.075      0.282   -1.31e+08    4.48e+08\n",
      "x356        8.574e+07   1.52e+08      0.564      0.573   -2.12e+08    3.84e+08\n",
      "x357         6.09e+08   1.24e+08      4.918      0.000    3.66e+08    8.52e+08\n",
      "x358        2.298e+08   1.41e+08      1.627      0.104    -4.7e+07    5.07e+08\n",
      "x359        6.038e+08   1.26e+08      4.785      0.000    3.56e+08    8.51e+08\n",
      "x360        4.119e+08    3.2e+08      1.287      0.198   -2.16e+08    1.04e+09\n",
      "x361       -2.481e+08   1.37e+08     -1.807      0.071   -5.17e+08     2.1e+07\n",
      "x362        3.544e+08   2.34e+08      1.514      0.130   -1.04e+08    8.13e+08\n",
      "x363        4.055e+07   1.51e+08      0.268      0.789   -2.56e+08    3.37e+08\n",
      "x364        4.937e+08   1.36e+08      3.643      0.000    2.28e+08    7.59e+08\n",
      "x365        2.208e+08   1.25e+08      1.772      0.076   -2.34e+07    4.65e+08\n",
      "x366       -2.064e+08   4.89e+08     -0.422      0.673   -1.17e+09    7.53e+08\n",
      "x367        3.708e+08   1.38e+08      2.686      0.007       1e+08    6.41e+08\n",
      "x368        4.491e+08   1.73e+08      2.597      0.009     1.1e+08    7.88e+08\n",
      "x369       -8.124e+07   1.69e+08     -0.481      0.631   -4.13e+08     2.5e+08\n",
      "x370        1.589e+08   1.28e+08      1.239      0.216   -9.25e+07     4.1e+08\n",
      "x371        3.558e+08   1.39e+08      2.569      0.010    8.44e+07    6.27e+08\n",
      "x372        2.211e+08   1.53e+08      1.446      0.148   -7.85e+07    5.21e+08\n",
      "x373        3.069e+08   1.35e+08      2.279      0.023     4.3e+07    5.71e+08\n",
      "x374        4.631e+08   1.48e+08      3.130      0.002    1.73e+08    7.53e+08\n",
      "x375       -1.705e+07   1.33e+08     -0.128      0.898   -2.78e+08    2.44e+08\n",
      "x376       -1.538e+08   1.44e+08     -1.070      0.285   -4.36e+08    1.28e+08\n",
      "x377       -1.311e+08   1.35e+08     -0.970      0.332   -3.96e+08    1.34e+08\n",
      "x378        9.848e+08   1.22e+08      8.083      0.000    7.46e+08    1.22e+09\n",
      "x379         2.62e+08   1.72e+08      1.524      0.127   -7.48e+07    5.99e+08\n",
      "x380       -2.066e+08    1.4e+08     -1.476      0.140   -4.81e+08    6.77e+07\n",
      "x381       -3.959e+07   3.25e+08     -0.122      0.903   -6.77e+08    5.98e+08\n",
      "x382       -3.238e+08   1.36e+08     -2.390      0.017   -5.89e+08   -5.82e+07\n",
      "x383        6.062e+08    1.2e+08      5.031      0.000     3.7e+08    8.42e+08\n",
      "x384        4.921e+08   1.19e+08      4.141      0.000    2.59e+08    7.25e+08\n",
      "x385       -1.152e+08   1.39e+08     -0.826      0.409   -3.88e+08    1.58e+08\n",
      "x386        9.576e+07   1.67e+08      0.574      0.566   -2.31e+08    4.23e+08\n",
      "x387        2.646e+08   1.43e+08      1.853      0.064   -1.53e+07    5.44e+08\n",
      "x388        -4.73e+07   1.38e+08     -0.344      0.731   -3.17e+08    2.22e+08\n",
      "x389       -1.206e+08   1.38e+08     -0.874      0.382   -3.91e+08     1.5e+08\n",
      "x390        1.847e+08   1.49e+08      1.237      0.216   -1.08e+08    4.77e+08\n",
      "x391        5.543e+07   1.44e+08      0.385      0.701   -2.27e+08    3.38e+08\n",
      "x392         3.47e+08   1.36e+08      2.558      0.011    8.11e+07    6.13e+08\n",
      "x393       -2.172e+08    1.5e+08     -1.446      0.148   -5.12e+08    7.72e+07\n",
      "x394        2.237e+08   1.39e+08      1.614      0.107    -4.8e+07    4.95e+08\n",
      "x395       -5.145e+08   1.55e+08     -3.324      0.001   -8.18e+08   -2.11e+08\n",
      "x396       -2.043e+08   1.74e+08     -1.174      0.240   -5.45e+08    1.37e+08\n",
      "x397        1.478e+08   1.55e+08      0.956      0.339   -1.55e+08    4.51e+08\n",
      "x398        4.154e+07   2.58e+08      0.161      0.872   -4.64e+08    5.47e+08\n",
      "x399        2.274e+07   1.35e+08      0.168      0.867   -2.43e+08    2.88e+08\n",
      "x400        7.097e+08   1.36e+08      5.232      0.000    4.44e+08    9.76e+08\n",
      "x401        4.033e+08   1.57e+08      2.562      0.010    9.47e+07    7.12e+08\n",
      "x402        6.686e+08    1.3e+08      5.141      0.000    4.14e+08    9.24e+08\n",
      "x403       -2.185e+08   1.31e+08     -1.672      0.094   -4.75e+08    3.76e+07\n",
      "x404        1.929e+08   1.51e+08      1.278      0.201   -1.03e+08    4.89e+08\n",
      "x405        4.171e+08   1.81e+08      2.300      0.021    6.16e+07    7.73e+08\n",
      "x406        9.146e+07   1.49e+08      0.614      0.539      -2e+08    3.83e+08\n",
      "x407        1.253e+08   1.57e+08      0.798      0.425   -1.82e+08    4.33e+08\n",
      "x408        2.694e+08   1.57e+08      1.716      0.086   -3.82e+07    5.77e+08\n",
      "x409        1.602e+09   1.49e+08     10.727      0.000    1.31e+09    1.89e+09\n",
      "x410        3.959e+08   1.28e+08      3.094      0.002    1.45e+08    6.47e+08\n",
      "x411        4.676e+08   1.24e+08      3.766      0.000    2.24e+08    7.11e+08\n",
      "x412        2.373e+08   1.62e+08      1.461      0.144   -8.11e+07    5.56e+08\n",
      "x413        8.985e+07   1.29e+08      0.698      0.485   -1.62e+08    3.42e+08\n",
      "x414         1.52e+08   1.53e+08      0.994      0.320   -1.48e+08    4.52e+08\n",
      "x415        3.193e+08    1.3e+08      2.457      0.014    6.46e+07    5.74e+08\n",
      "x416        8.667e+08   1.39e+08      6.254      0.000    5.95e+08    1.14e+09\n",
      "x417       -7.797e+07    1.6e+08     -0.486      0.627   -3.92e+08    2.36e+08\n",
      "x418        7.725e+08   1.25e+08      6.170      0.000    5.27e+08    1.02e+09\n",
      "x419        2.602e+08   1.43e+08      1.814      0.070   -2.09e+07    5.41e+08\n",
      "x420        3.541e+07   1.35e+08      0.262      0.793    -2.3e+08       3e+08\n",
      "x421        1.128e+08   1.62e+08      0.696      0.487   -2.05e+08    4.31e+08\n",
      "x422        4.367e+07   1.55e+08      0.281      0.778   -2.61e+08    3.48e+08\n",
      "x423        1.205e+08   1.44e+08      0.835      0.404   -1.62e+08    4.03e+08\n",
      "x424       -1.275e+07    1.5e+08     -0.085      0.932   -3.07e+08    2.82e+08\n",
      "x425        8.711e+07   1.46e+08      0.597      0.550   -1.99e+08    3.73e+08\n",
      "x426       -1.507e+08   1.41e+08     -1.069      0.285   -4.27e+08    1.26e+08\n",
      "x427        2.031e+08   1.39e+08      1.463      0.144   -6.91e+07    4.75e+08\n",
      "x428        4.079e+08   1.23e+08      3.320      0.001    1.67e+08    6.49e+08\n",
      "x429        5.598e+08   3.71e+08      1.509      0.131   -1.67e+08    1.29e+09\n",
      "x430         5.26e+06   1.39e+08      0.038      0.970   -2.67e+08    2.78e+08\n",
      "x431         3.58e+08   1.24e+08      2.881      0.004    1.14e+08    6.02e+08\n",
      "x432        3.853e+08   2.06e+08      1.867      0.062   -1.92e+07     7.9e+08\n",
      "x433        1.549e+08    1.2e+08      1.290      0.197   -8.05e+07     3.9e+08\n",
      "x434       -5.961e+08   1.69e+08     -3.536      0.000   -9.27e+08   -2.66e+08\n",
      "x435       -1.722e+06   1.28e+08     -0.013      0.989   -2.53e+08    2.49e+08\n",
      "x436        3.654e+08   1.29e+08      2.834      0.005    1.13e+08    6.18e+08\n",
      "x437       -3.982e+08   1.59e+08     -2.509      0.012   -7.09e+08   -8.72e+07\n",
      "x438       -2.412e+08   1.26e+08     -1.910      0.056   -4.89e+08    6.27e+06\n",
      "x439        -8.15e+07   2.58e+08     -0.316      0.752   -5.87e+08    4.24e+08\n",
      "x440         4.58e+05   1.26e+08      0.004      0.997   -2.46e+08    2.47e+08\n",
      "x441       -5.799e+08   1.97e+08     -2.942      0.003   -9.66e+08   -1.94e+08\n",
      "x442        3.094e+08   1.42e+08      2.181      0.029    3.14e+07    5.87e+08\n",
      "x443        5.698e+08   1.87e+08      3.047      0.002    2.03e+08    9.36e+08\n",
      "x444        2.955e+08   1.43e+08      2.060      0.039    1.44e+07    5.77e+08\n",
      "x445         6.68e+06    1.2e+08      0.056      0.956   -2.29e+08    2.42e+08\n",
      "x446       -1.392e+08   1.58e+08     -0.884      0.377   -4.48e+08    1.69e+08\n",
      "x447        2.029e+08   1.15e+08      1.758      0.079   -2.33e+07    4.29e+08\n",
      "x448        2.115e+08   2.14e+08      0.989      0.323   -2.08e+08    6.31e+08\n",
      "x449        3.282e+08   1.48e+08      2.214      0.027    3.76e+07    6.19e+08\n",
      "x450       -9.651e+08   1.83e+08     -5.265      0.000   -1.32e+09   -6.06e+08\n",
      "x451       -5.185e+07   1.88e+08     -0.275      0.783   -4.21e+08    3.17e+08\n",
      "x452        1.036e+09   1.28e+08      8.085      0.000    7.85e+08    1.29e+09\n",
      "x453        4.098e+06   1.53e+08      0.027      0.979   -2.95e+08    3.03e+08\n",
      "x454        5.005e+08    1.6e+08      3.127      0.002    1.87e+08    8.14e+08\n",
      "x455       -1.543e+08   1.96e+08     -0.786      0.432   -5.39e+08     2.3e+08\n",
      "x456       -5.282e+08   1.45e+08     -3.642      0.000   -8.13e+08   -2.44e+08\n",
      "x457        1.388e+07    1.5e+08      0.092      0.926    -2.8e+08    3.08e+08\n",
      "x458       -1.229e+08   1.37e+08     -0.896      0.370   -3.92e+08    1.46e+08\n",
      "x459       -4.818e+08   2.58e+08     -1.870      0.062   -9.87e+08    2.32e+07\n",
      "x460       -9.632e+07   1.42e+08     -0.680      0.496   -3.74e+08    1.81e+08\n",
      "x461       -1.084e+09   1.67e+08     -6.486      0.000   -1.41e+09   -7.56e+08\n",
      "x462       -6.213e+08   1.53e+08     -4.072      0.000    -9.2e+08   -3.22e+08\n",
      "x463        7.256e+08   1.42e+08      5.111      0.000    4.47e+08       1e+09\n",
      "x464       -1.319e+07    1.4e+08     -0.094      0.925   -2.87e+08     2.6e+08\n",
      "x465        9.717e+07   1.28e+08      0.757      0.449   -1.54e+08    3.49e+08\n",
      "x466        1.675e+08    1.6e+08      1.045      0.296   -1.47e+08    4.82e+08\n",
      "x467       -2.581e+08   1.26e+08     -2.041      0.041   -5.06e+08   -1.02e+07\n",
      "x468       -1.659e+07   1.67e+08     -0.100      0.921   -3.43e+08     3.1e+08\n",
      "x469       -4.419e+08   1.54e+08     -2.864      0.004   -7.44e+08   -1.39e+08\n",
      "x470       -7.568e+08   1.36e+08     -5.562      0.000   -1.02e+09    -4.9e+08\n",
      "x471       -4.531e+08   1.41e+08     -3.204      0.001    -7.3e+08   -1.76e+08\n",
      "x472       -9.486e+08   1.49e+08     -6.362      0.000   -1.24e+09   -6.56e+08\n",
      "x473        2.785e+08   1.32e+08      2.114      0.035    2.02e+07    5.37e+08\n",
      "x474       -2.177e+08   1.43e+08     -1.524      0.127   -4.98e+08    6.22e+07\n",
      "x475        8.556e+07   1.37e+08      0.625      0.532   -1.83e+08    3.54e+08\n",
      "x476       -2.992e+08   1.39e+08     -2.152      0.031   -5.72e+08   -2.67e+07\n",
      "x477       -3.892e+08   1.62e+08     -2.409      0.016   -7.06e+08   -7.25e+07\n",
      "x478        -3.31e+08   1.28e+08     -2.577      0.010   -5.83e+08   -7.92e+07\n",
      "x479        1.932e+08    1.4e+08      1.379      0.168   -8.14e+07    4.68e+08\n",
      "x480        5.323e+08   1.31e+08      4.061      0.000    2.75e+08    7.89e+08\n",
      "x481       -3.751e+06   1.96e+08     -0.019      0.985   -3.88e+08     3.8e+08\n",
      "x482       -4.346e+08   1.63e+08     -2.665      0.008   -7.54e+08   -1.15e+08\n",
      "x483        9.886e+06   1.85e+08      0.054      0.957   -3.52e+08    3.72e+08\n",
      "x484       -2.969e+07   3.36e+08     -0.088      0.930   -6.88e+08    6.28e+08\n",
      "x485       -6.772e+08   1.39e+08     -4.871      0.000    -9.5e+08   -4.05e+08\n",
      "x486       -2.616e+08   1.38e+08     -1.895      0.058   -5.32e+08    9.04e+06\n",
      "x487       -7.316e+08    3.7e+08     -1.977      0.048   -1.46e+09   -6.15e+06\n",
      "x488       -1.635e+08   1.66e+08     -0.983      0.326   -4.89e+08    1.62e+08\n",
      "x489       -1.478e+07   1.57e+08     -0.094      0.925   -3.22e+08    2.93e+08\n",
      "x490       -3.332e+08   1.33e+08     -2.496      0.013   -5.95e+08   -7.16e+07\n",
      "x491       -5.939e+07   1.36e+08     -0.436      0.663   -3.27e+08    2.08e+08\n",
      "x492        8.352e+08   1.54e+08      5.427      0.000    5.34e+08    1.14e+09\n",
      "x493        2.617e+08   1.45e+08      1.800      0.072   -2.33e+07    5.47e+08\n",
      "x494       -3.678e+07   1.75e+08     -0.210      0.834    -3.8e+08    3.06e+08\n",
      "x495       -9.472e+07   1.42e+08     -0.668      0.504   -3.73e+08    1.83e+08\n",
      "x496        5.684e+08   1.32e+08      4.308      0.000     3.1e+08    8.27e+08\n",
      "x497       -3.773e+07   1.27e+08     -0.298      0.766   -2.86e+08    2.11e+08\n",
      "x498        4.868e+08   1.23e+08      3.968      0.000    2.46e+08    7.27e+08\n",
      "x499       -5.572e+07   1.33e+08     -0.419      0.675   -3.16e+08    2.05e+08\n",
      "x500        2.111e+08    1.3e+08      1.623      0.105   -4.39e+07    4.66e+08\n",
      "x501        5.395e+07   1.43e+08      0.378      0.706   -2.26e+08    3.34e+08\n",
      "x502        6.148e+08   1.52e+08      4.055      0.000    3.18e+08    9.12e+08\n",
      "x503       -1.285e+08   1.53e+08     -0.838      0.402   -4.29e+08    1.72e+08\n",
      "x504       -4.574e+08   1.66e+08     -2.754      0.006   -7.83e+08   -1.32e+08\n",
      "x505        5.387e+08   2.08e+08      2.592      0.010    1.31e+08    9.46e+08\n",
      "x506        1.127e+08    1.4e+08      0.804      0.421   -1.62e+08    3.87e+08\n",
      "x507        3.143e+08   1.64e+08      1.917      0.055   -7.04e+06    6.36e+08\n",
      "x508        5.446e+07   1.35e+08      0.402      0.688   -2.11e+08     3.2e+08\n",
      "x509        6.541e+08   1.48e+08      4.416      0.000    3.64e+08    9.44e+08\n",
      "x510        5.262e+08   1.67e+08      3.157      0.002       2e+08    8.53e+08\n",
      "x511        3.903e+08   1.43e+08      2.726      0.006     1.1e+08    6.71e+08\n",
      "x512        4.259e+08   1.97e+08      2.164      0.030    4.01e+07    8.12e+08\n",
      "x513        3.232e+08   1.45e+08      2.236      0.025    3.99e+07    6.06e+08\n",
      "x514       -3.342e+07   1.57e+08     -0.212      0.832   -3.42e+08    2.75e+08\n",
      "x515        4.709e+08   1.31e+08      3.599      0.000    2.14e+08    7.27e+08\n",
      "x516        2.124e+08   1.19e+08      1.788      0.074   -2.05e+07    4.45e+08\n",
      "x517       -1.556e+08   1.37e+08     -1.136      0.256   -4.24e+08    1.13e+08\n",
      "x518       -1.059e+09   3.25e+08     -3.256      0.001    -1.7e+09   -4.21e+08\n",
      "x519       -2.639e+08   1.24e+08     -2.130      0.033   -5.07e+08    -2.1e+07\n",
      "x520        1.187e+08   1.26e+08      0.943      0.346   -1.28e+08    3.65e+08\n",
      "x521       -1.148e+08   1.15e+08     -1.001      0.317    -3.4e+08     1.1e+08\n",
      "x522       -9.288e+08   2.85e+08     -3.255      0.001   -1.49e+09    -3.7e+08\n",
      "x523       -2.473e+08    1.7e+08     -1.457      0.145    -5.8e+08    8.54e+07\n",
      "x524        1.621e+08   1.29e+08      1.260      0.208   -9.01e+07    4.14e+08\n",
      "x525       -7.102e+08   2.12e+08     -3.358      0.001   -1.12e+09   -2.96e+08\n",
      "x526       -4.963e+08   1.58e+08     -3.138      0.002   -8.06e+08   -1.86e+08\n",
      "x527       -7.507e+08   1.27e+08     -5.930      0.000   -9.99e+08   -5.03e+08\n",
      "x528       -6.266e+08   1.36e+08     -4.603      0.000   -8.93e+08    -3.6e+08\n",
      "x529       -6.534e+08   1.45e+08     -4.510      0.000   -9.37e+08   -3.69e+08\n",
      "x530       -7.286e+08   1.44e+08     -5.059      0.000   -1.01e+09   -4.46e+08\n",
      "x531       -2.802e+08    1.3e+08     -2.156      0.031   -5.35e+08   -2.55e+07\n",
      "x532        1.468e+08   1.25e+08      1.176      0.240   -9.79e+07    3.92e+08\n",
      "x533       -2.151e+07   1.62e+08     -0.133      0.895   -3.39e+08    2.96e+08\n",
      "x534        4.317e+07   1.79e+08      0.241      0.809   -3.07e+08    3.94e+08\n",
      "x535        1.134e+08   1.61e+08      0.704      0.481   -2.02e+08    4.29e+08\n",
      "x536       -5.148e+07   1.82e+08     -0.282      0.778   -4.09e+08    3.06e+08\n",
      "x537        1.981e+08   1.24e+08      1.598      0.110   -4.49e+07    4.41e+08\n",
      "x538       -1.547e+08   3.09e+08     -0.501      0.616   -7.59e+08     4.5e+08\n",
      "x539       -1.778e+07   1.38e+08     -0.129      0.898   -2.89e+08    2.53e+08\n",
      "x540       -1.088e+07   1.47e+08     -0.074      0.941   -2.99e+08    2.77e+08\n",
      "x541        1.874e+08   1.28e+08      1.467      0.142   -6.29e+07    4.38e+08\n",
      "x542       -1.049e+08   1.47e+08     -0.716      0.474   -3.92e+08    1.82e+08\n",
      "x543        4.847e+08   1.39e+08      3.484      0.000    2.12e+08    7.57e+08\n",
      "x544       -1.231e+08   2.48e+08     -0.496      0.620   -6.09e+08    3.63e+08\n",
      "x545        1.129e+08   1.31e+08      0.863      0.388   -1.43e+08    3.69e+08\n",
      "x546        3.741e+08   2.29e+08      1.636      0.102   -7.41e+07    8.22e+08\n",
      "x547        1.402e+08   1.43e+08      0.983      0.326   -1.39e+08     4.2e+08\n",
      "x548        1.273e+08   1.33e+08      0.959      0.337   -1.33e+08    3.87e+08\n",
      "x549        7.113e+08   1.41e+08      5.050      0.000    4.35e+08    9.87e+08\n",
      "x550         2.42e+08   1.33e+08      1.823      0.068   -1.82e+07    5.02e+08\n",
      "x551        2.793e+08   1.78e+08      1.569      0.117   -6.96e+07    6.28e+08\n",
      "x552        2.992e+08   1.35e+08      2.218      0.027    3.48e+07    5.64e+08\n",
      "x553        3.569e+08   1.67e+08      2.134      0.033    2.91e+07    6.85e+08\n",
      "x554        1.712e+08    1.3e+08      1.315      0.189    -8.4e+07    4.26e+08\n",
      "x555        4.952e+08   1.42e+08      3.493      0.000    2.17e+08    7.73e+08\n",
      "x556        4.717e+07   2.14e+08      0.221      0.825   -3.72e+08    4.66e+08\n",
      "x557        2.477e+07   1.24e+08      0.200      0.841   -2.18e+08    2.67e+08\n",
      "x558       -3.701e+08   1.33e+08     -2.784      0.005   -6.31e+08    -1.1e+08\n",
      "x559        3.289e+08   1.24e+08      2.646      0.008    8.52e+07    5.72e+08\n",
      "x560       -9.799e+07   1.79e+08     -0.547      0.584   -4.49e+08    2.53e+08\n",
      "x561        1.067e+09   1.38e+08      7.718      0.000    7.96e+08    1.34e+09\n",
      "x562        4.939e+08    1.6e+08      3.090      0.002    1.81e+08    8.07e+08\n",
      "x563       -1.385e+08   1.58e+08     -0.878      0.380   -4.48e+08    1.71e+08\n",
      "x564        4.816e+07   1.27e+08      0.378      0.705   -2.01e+08    2.98e+08\n",
      "x565        4.376e+08   1.29e+08      3.384      0.001    1.84e+08    6.91e+08\n",
      "x566       -4.845e+06   1.57e+08     -0.031      0.975   -3.12e+08    3.03e+08\n",
      "x567        4.581e+08   1.36e+08      3.357      0.001    1.91e+08    7.26e+08\n",
      "x568        2.299e+08   1.67e+08      1.376      0.169   -9.76e+07    5.57e+08\n",
      "x569        2.482e+08   1.73e+08      1.432      0.152   -9.14e+07    5.88e+08\n",
      "x570        1.453e+08   1.98e+08      0.734      0.463   -2.43e+08    5.34e+08\n",
      "x571        1.932e+08   1.32e+08      1.463      0.144   -6.57e+07    4.52e+08\n",
      "x572       -1.005e+08   1.84e+08     -0.545      0.585   -4.61e+08    2.61e+08\n",
      "x573       -5.357e+07   1.41e+08     -0.379      0.705   -3.31e+08    2.24e+08\n",
      "x574        2.782e+08   1.52e+08      1.829      0.067   -1.99e+07    5.76e+08\n",
      "x575         2.76e+08   1.34e+08      2.058      0.040    1.32e+07    5.39e+08\n",
      "x576       -1.539e+08   1.36e+08     -1.128      0.259   -4.21e+08    1.14e+08\n",
      "x577       -8.993e+07   1.37e+08     -0.655      0.513   -3.59e+08    1.79e+08\n",
      "x578        5.188e+08   1.24e+08      4.193      0.000    2.76e+08    7.61e+08\n",
      "x579        3.196e+08   2.46e+08      1.300      0.194   -1.62e+08    8.02e+08\n",
      "x580        5.391e+08   1.28e+08      4.215      0.000    2.88e+08     7.9e+08\n",
      "x581       -7.197e+06   1.53e+08     -0.047      0.962   -3.06e+08    2.92e+08\n",
      "x582        5.258e+08   1.65e+08      3.188      0.001    2.03e+08    8.49e+08\n",
      "x583       -4.502e+08   1.34e+08     -3.369      0.001   -7.12e+08   -1.88e+08\n",
      "x584        2.471e+08   1.44e+08      1.713      0.087   -3.57e+07     5.3e+08\n",
      "x585        2.622e+08   1.72e+08      1.522      0.128   -7.54e+07       6e+08\n",
      "x586        5.392e+08   1.21e+08      4.464      0.000    3.02e+08    7.76e+08\n",
      "x587        5.407e+07   1.42e+08      0.380      0.704   -2.25e+08    3.33e+08\n",
      "x588        1.124e+08   1.79e+08      0.628      0.530   -2.38e+08    4.63e+08\n",
      "x589        1.894e+08   1.26e+08      1.504      0.133   -5.74e+07    4.36e+08\n",
      "x590        7.534e+08   1.18e+08      6.368      0.000    5.22e+08    9.85e+08\n",
      "x591        2.129e+07   1.37e+08      0.155      0.877   -2.48e+08     2.9e+08\n",
      "x592        2.381e+08   1.37e+08      1.742      0.081   -2.98e+07    5.06e+08\n",
      "x593       -2.019e+08   1.64e+08     -1.230      0.219   -5.24e+08     1.2e+08\n",
      "x594       -3.767e+08   1.25e+08     -3.016      0.003   -6.22e+08   -1.32e+08\n",
      "x595       -1.751e+07   1.21e+08     -0.145      0.885   -2.55e+08     2.2e+08\n",
      "x596       -1.716e+08   1.37e+08     -1.253      0.210    -4.4e+08    9.68e+07\n",
      "x597        3.916e+08   1.79e+08      2.183      0.029    4.01e+07    7.43e+08\n",
      "x598        4.446e+08   1.38e+08      3.233      0.001    1.75e+08    7.14e+08\n",
      "x599        2.327e+08   1.98e+08      1.176      0.239   -1.55e+08    6.21e+08\n",
      "x600        2.028e+08   1.79e+08      1.136      0.256   -1.47e+08    5.53e+08\n",
      "x601        2.457e+08   1.24e+08      1.977      0.048    2.12e+06    4.89e+08\n",
      "x602        2.994e+08   1.36e+08      2.203      0.028     3.3e+07    5.66e+08\n",
      "x603       -1.935e+08   1.27e+08     -1.529      0.126   -4.41e+08    5.45e+07\n",
      "x604        2.161e+08   1.25e+08      1.723      0.085   -2.97e+07    4.62e+08\n",
      "x605         1.17e+08   1.35e+08      0.865      0.387   -1.48e+08    3.82e+08\n",
      "x606       -4.426e+07   1.21e+08     -0.364      0.716   -2.82e+08    1.94e+08\n",
      "x607        5.885e+07   2.89e+08      0.203      0.839   -5.08e+08    6.26e+08\n",
      "x608        1.148e+08   1.65e+08      0.695      0.487   -2.09e+08    4.39e+08\n",
      "x609        7.853e+08   1.51e+08      5.206      0.000     4.9e+08    1.08e+09\n",
      "x610        -6.68e+06    1.9e+08     -0.035      0.972   -3.78e+08    3.65e+08\n",
      "x611        6.951e+07   1.56e+08      0.446      0.656   -2.36e+08    3.75e+08\n",
      "x612        9.341e+08   1.21e+08      7.700      0.000    6.96e+08    1.17e+09\n",
      "x613       -5.726e+07   1.31e+08     -0.439      0.661   -3.13e+08    1.99e+08\n",
      "x614         1.89e+08    1.2e+08      1.571      0.116   -4.68e+07    4.25e+08\n",
      "x615        2.125e+08   1.46e+08      1.453      0.146   -7.41e+07    4.99e+08\n",
      "x616        2.518e+07   1.54e+08      0.163      0.870   -2.77e+08    3.28e+08\n",
      "x617       -2.025e+08    1.3e+08     -1.552      0.121   -4.58e+08    5.32e+07\n",
      "x618        2.499e+08   1.17e+08      2.136      0.033    2.06e+07    4.79e+08\n",
      "x619        4.279e+06   1.31e+08      0.033      0.974   -2.53e+08    2.61e+08\n",
      "x620        2.025e+08   1.45e+08      1.400      0.161   -8.09e+07    4.86e+08\n",
      "x621        4.493e+07   1.51e+08      0.298      0.766   -2.51e+08     3.4e+08\n",
      "x622         -1.9e+07   1.61e+08     -0.118      0.906   -3.35e+08    2.97e+08\n",
      "x623         4.65e+08   1.64e+08      2.841      0.004    1.44e+08    7.86e+08\n",
      "x624        6.239e+08   1.59e+08      3.918      0.000    3.12e+08    9.36e+08\n",
      "x625        9.117e+07   1.53e+08      0.594      0.553    -2.1e+08    3.92e+08\n",
      "x626        6.601e+07   1.72e+08      0.385      0.701    -2.7e+08    4.02e+08\n",
      "x627        6.449e+07   1.61e+08      0.401      0.688    -2.5e+08    3.79e+08\n",
      "x628       -2.958e+08   1.44e+08     -2.051      0.040   -5.78e+08   -1.31e+07\n",
      "x629        4.523e+07   1.65e+08      0.274      0.784   -2.78e+08    3.69e+08\n",
      "x630       -3.891e+08   1.39e+08     -2.795      0.005   -6.62e+08   -1.16e+08\n",
      "x631         4.06e+08   1.39e+08      2.923      0.003    1.34e+08    6.78e+08\n",
      "x632       -6.258e+08    1.3e+08     -4.815      0.000   -8.81e+08   -3.71e+08\n",
      "x633        9.814e+07    1.6e+08      0.614      0.539   -2.15e+08    4.11e+08\n",
      "x634       -4.166e+08   1.78e+08     -2.337      0.019   -7.66e+08   -6.72e+07\n",
      "x635        1.252e+09   1.31e+08      9.589      0.000    9.96e+08    1.51e+09\n",
      "x636        7.233e+04   1.39e+08      0.001      1.000   -2.73e+08    2.73e+08\n",
      "x637        8.573e+08    1.5e+08      5.722      0.000    5.64e+08    1.15e+09\n",
      "x638       -2.241e+08   1.46e+08     -1.531      0.126   -5.11e+08    6.27e+07\n",
      "x639        3.919e+08   1.45e+08      2.709      0.007    1.08e+08    6.76e+08\n",
      "x640        7.278e+07   1.82e+08      0.400      0.689   -2.84e+08    4.29e+08\n",
      "x641        1.634e+08    1.4e+08      1.171      0.242    -1.1e+08    4.37e+08\n",
      "x642        2.223e+09   1.22e+08     18.151      0.000    1.98e+09    2.46e+09\n",
      "x643        6.904e+08   1.63e+08      4.230      0.000     3.7e+08    1.01e+09\n",
      "x644        3.835e+08   1.35e+08      2.850      0.004     1.2e+08    6.47e+08\n",
      "x645        2.598e+07   1.36e+08      0.191      0.849   -2.41e+08    2.93e+08\n",
      "x646        1.071e+08   1.54e+08      0.695      0.487   -1.95e+08    4.09e+08\n",
      "x647        -8.21e+08   2.74e+08     -2.992      0.003   -1.36e+09   -2.83e+08\n",
      "x648        2.191e+08   1.24e+08      1.774      0.076   -2.29e+07    4.61e+08\n",
      "x649        1.825e+07   1.95e+08      0.093      0.926   -3.65e+08    4.01e+08\n",
      "x650       -1.263e+08    1.6e+08     -0.789      0.430    -4.4e+08    1.88e+08\n",
      "x651       -5.487e+07   1.21e+08     -0.454      0.650   -2.92e+08    1.82e+08\n",
      "x652        2.142e+08   1.72e+08      1.247      0.212   -1.22e+08    5.51e+08\n",
      "x653        1.077e+08   1.52e+08      0.710      0.477    -1.9e+08    4.05e+08\n",
      "x654        1.318e+07   1.68e+08      0.079      0.937   -3.15e+08    3.42e+08\n",
      "x655       -2.044e+08   2.45e+08     -0.834      0.404   -6.85e+08    2.76e+08\n",
      "x656        1.753e+08   1.69e+08      1.040      0.298   -1.55e+08    5.06e+08\n",
      "x657       -1.724e+08   1.44e+08     -1.193      0.233   -4.56e+08    1.11e+08\n",
      "x658        4.248e+08   1.33e+08      3.202      0.001    1.65e+08    6.85e+08\n",
      "x659        6.796e+08   1.34e+08      5.087      0.000    4.18e+08    9.41e+08\n",
      "x660        2.678e+08   1.48e+08      1.805      0.071    -2.3e+07    5.59e+08\n",
      "x661        5.779e+08   1.37e+08      4.204      0.000    3.08e+08    8.47e+08\n",
      "x662        4.717e+08   1.55e+08      3.035      0.002    1.67e+08    7.76e+08\n",
      "x663        2.309e+08   1.55e+08      1.488      0.137   -7.33e+07    5.35e+08\n",
      "x664        7.308e+08   1.34e+08      5.470      0.000    4.69e+08    9.93e+08\n",
      "x665       -7.651e+05   1.56e+08     -0.005      0.996   -3.06e+08    3.05e+08\n",
      "x666        8.362e+08   2.01e+08      4.167      0.000    4.43e+08    1.23e+09\n",
      "x667         2.72e+08   1.63e+08      1.672      0.095   -4.69e+07    5.91e+08\n",
      "x668        5.017e+08   1.75e+08      2.870      0.004    1.59e+08    8.44e+08\n",
      "x669        4.554e+08   1.29e+08      3.541      0.000    2.03e+08    7.07e+08\n",
      "x670        3.825e+08   1.45e+08      2.637      0.008    9.82e+07    6.67e+08\n",
      "x671        5.002e+08   1.35e+08      3.704      0.000    2.35e+08    7.65e+08\n",
      "x672       -1.978e+08   1.29e+08     -1.535      0.125    -4.5e+08    5.47e+07\n",
      "x673        2.162e+08   1.66e+08      1.299      0.194    -1.1e+08    5.42e+08\n",
      "x674        2.556e+08   1.36e+08      1.884      0.060   -1.03e+07    5.22e+08\n",
      "x675        2.605e+08   1.47e+08      1.775      0.076   -2.71e+07    5.48e+08\n",
      "x676        3.615e+08   1.52e+08      2.378      0.017    6.35e+07    6.59e+08\n",
      "x677        8.888e+07   1.43e+08      0.624      0.533    -1.9e+08    3.68e+08\n",
      "x678        2.912e+08   1.53e+08      1.909      0.056   -7.74e+06     5.9e+08\n",
      "x679        1.886e+08   2.06e+08      0.918      0.359   -2.14e+08    5.91e+08\n",
      "x680        4.256e+08   1.41e+08      3.024      0.002     1.5e+08    7.01e+08\n",
      "x681       -9.503e+07   1.37e+08     -0.692      0.489   -3.64e+08    1.74e+08\n",
      "x682       -7.915e+08   1.69e+08     -4.694      0.000   -1.12e+09   -4.61e+08\n",
      "x683       -1.898e+08      2e+08     -0.950      0.342   -5.82e+08    2.02e+08\n",
      "x684       -2.304e+08   2.74e+08     -0.841      0.400   -7.68e+08    3.07e+08\n",
      "x685       -5.837e+08    1.5e+08     -3.886      0.000   -8.78e+08   -2.89e+08\n",
      "x686       -3.995e+08   1.27e+08     -3.148      0.002   -6.48e+08   -1.51e+08\n",
      "x687       -5.289e+08   1.38e+08     -3.835      0.000   -7.99e+08   -2.59e+08\n",
      "x688       -2.641e+08    1.3e+08     -2.027      0.043   -5.19e+08   -8.76e+06\n",
      "x689       -4.771e+08   1.44e+08     -3.314      0.001   -7.59e+08   -1.95e+08\n",
      "x690        -1.33e+08    1.3e+08     -1.021      0.307   -3.88e+08    1.22e+08\n",
      "x691        4.726e+07    1.3e+08      0.364      0.716   -2.07e+08    3.02e+08\n",
      "x692       -1.367e+08   1.45e+08     -0.939      0.348   -4.22e+08    1.49e+08\n",
      "x693       -2.954e+07   1.41e+08     -0.210      0.834   -3.05e+08    2.46e+08\n",
      "x694        5.948e+07    1.5e+08      0.397      0.691   -2.34e+08    3.53e+08\n",
      "x695       -1.623e+08   1.56e+08     -1.040      0.298   -4.68e+08    1.44e+08\n",
      "x696       -1.721e+08    1.4e+08     -1.233      0.218   -4.46e+08    1.01e+08\n",
      "x697       -2.421e+08    1.8e+08     -1.344      0.179   -5.95e+08    1.11e+08\n",
      "x698       -5.599e+08   1.86e+08     -3.003      0.003   -9.25e+08   -1.94e+08\n",
      "x699         4.23e+07   2.15e+08      0.197      0.844   -3.78e+08    4.63e+08\n",
      "x700        9.232e+07   1.53e+08      0.603      0.546   -2.08e+08    3.92e+08\n",
      "x701        8.089e+07    1.4e+08      0.579      0.562   -1.93e+08    3.55e+08\n",
      "x702        2.402e+08   1.52e+08      1.581      0.114   -5.76e+07    5.38e+08\n",
      "x703        8.251e+07   1.31e+08      0.628      0.530   -1.75e+08     3.4e+08\n",
      "x704         1.37e+08   1.56e+08      0.879      0.380   -1.69e+08    4.42e+08\n",
      "x705        9.149e+08    1.4e+08      6.516      0.000     6.4e+08    1.19e+09\n",
      "x706        5.436e+08   1.36e+08      4.001      0.000    2.77e+08     8.1e+08\n",
      "x707         9.14e+07   1.62e+08      0.565      0.572   -2.26e+08    4.08e+08\n",
      "x708       -4.657e+08   1.15e+08     -4.048      0.000   -6.91e+08    -2.4e+08\n",
      "x709       -1.389e+08    1.3e+08     -1.071      0.284   -3.93e+08    1.15e+08\n",
      "x710        1.643e+08   1.32e+08      1.242      0.214   -9.51e+07    4.24e+08\n",
      "x711       -2.337e+08   1.79e+08     -1.308      0.191   -5.84e+08    1.16e+08\n",
      "x712        5.819e+07   1.57e+08      0.372      0.710   -2.49e+08    3.65e+08\n",
      "x713       -1.788e+08   2.02e+08     -0.886      0.376   -5.74e+08    2.17e+08\n",
      "x714       -3.775e+08   2.21e+08     -1.708      0.088   -8.11e+08    5.57e+07\n",
      "x715       -3.456e+08   1.62e+08     -2.135      0.033   -6.63e+08   -2.84e+07\n",
      "x716       -6.678e+07   1.61e+08     -0.415      0.678   -3.82e+08    2.48e+08\n",
      "x717        2.018e+08   1.27e+08      1.592      0.111   -4.67e+07     4.5e+08\n",
      "x718         1.75e+08   1.43e+08      1.222      0.222   -1.06e+08    4.56e+08\n",
      "x719       -4.073e+08   2.04e+08     -1.992      0.046   -8.08e+08   -6.64e+06\n",
      "x720       -9.507e+07   1.56e+08     -0.611      0.541      -4e+08     2.1e+08\n",
      "x721        4.189e+07   1.55e+08      0.271      0.787   -2.61e+08    3.45e+08\n",
      "x722       -3.645e+07   1.42e+08     -0.256      0.798   -3.15e+08    2.43e+08\n",
      "x723        1.461e+08    4.6e+08      0.318      0.751   -7.55e+08    1.05e+09\n",
      "x724       -7.788e+08   3.45e+08     -2.255      0.024   -1.46e+09   -1.02e+08\n",
      "x725       -2.878e+08   1.55e+08     -1.851      0.064   -5.93e+08     1.7e+07\n",
      "x726        1.053e+08   1.26e+08      0.838      0.402   -1.41e+08    3.52e+08\n",
      "x727       -3.219e+06   2.14e+08     -0.015      0.988   -4.22e+08    4.16e+08\n",
      "x728       -1.582e+08   1.49e+08     -1.059      0.289   -4.51e+08    1.34e+08\n",
      "x729        1.777e+08   1.31e+08      1.354      0.176   -7.95e+07    4.35e+08\n",
      "x730        5.008e+08   1.34e+08      3.741      0.000    2.38e+08    7.63e+08\n",
      "x731        1.813e+08   1.28e+08      1.413      0.158   -7.01e+07    4.33e+08\n",
      "x732        3.081e+08   1.79e+08      1.719      0.086   -4.32e+07    6.59e+08\n",
      "x733       -2.505e+08   1.89e+08     -1.328      0.184    -6.2e+08    1.19e+08\n",
      "x734       -7.845e+07    2.4e+08     -0.327      0.744   -5.49e+08    3.92e+08\n",
      "x735         -1.2e+08   1.46e+08     -0.821      0.411   -4.06e+08    1.66e+08\n",
      "x736         1.66e+08   1.32e+08      1.257      0.209   -9.28e+07    4.25e+08\n",
      "x737        3.813e+08   1.36e+08      2.803      0.005    1.15e+08    6.48e+08\n",
      "x738        1.954e+08   1.38e+08      1.417      0.157   -7.49e+07    4.66e+08\n",
      "x739        -1.78e+08   1.41e+08     -1.261      0.207   -4.55e+08    9.87e+07\n",
      "x740       -6.697e+08   2.86e+08     -2.344      0.019   -1.23e+09    -1.1e+08\n",
      "x741       -1.189e+08   1.15e+08     -1.031      0.303   -3.45e+08    1.07e+08\n",
      "x742       -4.026e+08   1.32e+08     -3.053      0.002   -6.61e+08   -1.44e+08\n",
      "x743        7.296e+07   1.87e+08      0.390      0.696   -2.94e+08     4.4e+08\n",
      "x744       -3.863e+08   1.41e+08     -2.743      0.006   -6.62e+08    -1.1e+08\n",
      "x745       -1.543e+08    1.7e+08     -0.907      0.365   -4.88e+08    1.79e+08\n",
      "x746       -3.732e+07   1.31e+08     -0.286      0.775   -2.93e+08    2.19e+08\n",
      "x747        1.258e+08   1.98e+08      0.635      0.525   -2.62e+08    5.14e+08\n",
      "x748       -5.487e+08   2.09e+08     -2.627      0.009   -9.58e+08   -1.39e+08\n",
      "x749       -4.379e+08   2.17e+08     -2.014      0.044   -8.64e+08   -1.16e+07\n",
      "x750        3.916e+06   1.59e+08      0.025      0.980   -3.07e+08    3.15e+08\n",
      "x751       -2.305e+08   1.48e+08     -1.556      0.120   -5.21e+08    5.99e+07\n",
      "x752       -5.513e+08   1.47e+08     -3.746      0.000    -8.4e+08   -2.63e+08\n",
      "x753        -6.88e+08   1.46e+08     -4.721      0.000   -9.74e+08   -4.02e+08\n",
      "x754        8.329e+07   1.37e+08      0.606      0.545   -1.86e+08    3.53e+08\n",
      "x755        5.601e+08    1.3e+08      4.325      0.000    3.06e+08    8.14e+08\n",
      "x756       -6.001e+08   1.29e+08     -4.646      0.000   -8.53e+08   -3.47e+08\n",
      "x757       -3.616e+07   2.01e+08     -0.180      0.857    -4.3e+08    3.57e+08\n",
      "x758        3.214e+08   1.48e+08      2.166      0.030    3.05e+07    6.12e+08\n",
      "x759       -7.526e+07   1.28e+08     -0.589      0.556   -3.26e+08    1.75e+08\n",
      "x760       -8.758e+08   4.39e+08     -1.995      0.046   -1.74e+09   -1.52e+07\n",
      "x761       -7.953e+08   1.98e+08     -4.008      0.000   -1.18e+09   -4.06e+08\n",
      "x762       -1.188e+08   3.18e+08     -0.374      0.709   -7.42e+08    5.04e+08\n",
      "x763        3.112e+08   1.55e+08      2.003      0.045    6.74e+06    6.16e+08\n",
      "x764        5.947e+08   1.37e+08      4.327      0.000    3.25e+08    8.64e+08\n",
      "x765       -1.745e+08   2.21e+08     -0.791      0.429   -6.07e+08    2.58e+08\n",
      "x766        -1.73e+08   1.22e+08     -1.423      0.155   -4.11e+08    6.54e+07\n",
      "x767        6.883e+07   1.32e+08      0.520      0.603   -1.91e+08    3.28e+08\n",
      "x768        1.005e+08   2.04e+08      0.492      0.622      -3e+08       5e+08\n",
      "x769        7.958e+07   2.16e+08      0.368      0.713   -3.44e+08    5.03e+08\n",
      "x770        9.068e+07   1.39e+08      0.650      0.516   -1.83e+08    3.64e+08\n",
      "x771       -1.184e+09   1.84e+08     -6.437      0.000   -1.54e+09   -8.24e+08\n",
      "x772        5.691e+08   1.51e+08      3.774      0.000    2.74e+08    8.65e+08\n",
      "x773       -1.366e+08   3.09e+08     -0.441      0.659   -7.43e+08     4.7e+08\n",
      "x774         1.15e+07   1.61e+08      0.072      0.943   -3.03e+08    3.26e+08\n",
      "x775         1.44e+08   1.45e+08      0.994      0.320    -1.4e+08    4.28e+08\n",
      "x776       -2.417e+08   1.81e+08     -1.334      0.182   -5.97e+08    1.14e+08\n",
      "x777        8.863e+07   1.42e+08      0.626      0.532   -1.89e+08    3.66e+08\n",
      "x778        3.088e+08   1.58e+08      1.956      0.050    -6.2e+05    6.18e+08\n",
      "x779        6.214e+08   1.34e+08      4.631      0.000    3.58e+08    8.84e+08\n",
      "x780        1.589e+08   1.47e+08      1.078      0.281    -1.3e+08    4.48e+08\n",
      "x781       -9.874e+07   1.27e+08     -0.779      0.436   -3.47e+08     1.5e+08\n",
      "x782        3.801e+08   1.98e+08      1.920      0.055      -8e+06    7.68e+08\n",
      "x783        4.211e+08   1.34e+08      3.152      0.002    1.59e+08    6.83e+08\n",
      "x784        2.312e+08   1.59e+08      1.454      0.146   -8.04e+07    5.43e+08\n",
      "x785        -3.19e+08   2.09e+08     -1.527      0.127   -7.28e+08    9.04e+07\n",
      "x786       -8.414e+07   1.54e+08     -0.546      0.585   -3.86e+08    2.18e+08\n",
      "x787         3.04e+06   1.79e+08      0.017      0.986   -3.48e+08    3.54e+08\n",
      "x788        1.971e+08   1.52e+08      1.297      0.195   -1.01e+08    4.95e+08\n",
      "x789        3.714e+08   1.37e+08      2.719      0.007    1.04e+08    6.39e+08\n",
      "x790        5.547e+07   1.41e+08      0.394      0.694   -2.21e+08    3.32e+08\n",
      "x791        2.776e+08   1.25e+08      2.213      0.027    3.18e+07    5.23e+08\n",
      "x792        5.425e+08   1.67e+08      3.241      0.001    2.14e+08    8.71e+08\n",
      "x793        3.041e+08   1.31e+08      2.316      0.021    4.68e+07    5.61e+08\n",
      "x794        2.649e+08    1.2e+08      2.201      0.028     2.9e+07    5.01e+08\n",
      "x795        3.351e+08    1.3e+08      2.584      0.010     8.1e+07    5.89e+08\n",
      "x796        1.407e+08   1.44e+08      0.980      0.327   -1.41e+08    4.22e+08\n",
      "x797        2.297e+08   1.49e+08      1.539      0.124   -6.28e+07    5.22e+08\n",
      "x798        3.433e+08   1.31e+08      2.620      0.009    8.65e+07       6e+08\n",
      "x799        -1.11e+08   2.11e+08     -0.527      0.598   -5.24e+08    3.02e+08\n",
      "x800        2.574e+08   1.37e+08      1.874      0.061   -1.19e+07    5.27e+08\n",
      "x801        -2.55e+07   1.59e+08     -0.160      0.873   -3.37e+08    2.86e+08\n",
      "x802        2.106e+08   1.26e+08      1.666      0.096   -3.72e+07    4.58e+08\n",
      "x803       -1.827e+08   5.63e+08     -0.324      0.746   -1.29e+09    9.22e+08\n",
      "x804       -1.885e+08   1.44e+08     -1.308      0.191   -4.71e+08    9.41e+07\n",
      "x805        2.834e+08   1.72e+08      1.649      0.099   -5.34e+07     6.2e+08\n",
      "x806         2.33e+08   2.26e+08      1.033      0.302   -2.09e+08    6.75e+08\n",
      "x807        4.858e+08    1.4e+08      3.466      0.001    2.11e+08    7.61e+08\n",
      "x808         7.36e+07    1.7e+08      0.434      0.664   -2.59e+08    4.06e+08\n",
      "x809        1.803e+08   2.05e+08      0.881      0.378   -2.21e+08    5.82e+08\n",
      "x810         5.95e+07   1.46e+08      0.407      0.684   -2.27e+08    3.46e+08\n",
      "x811        4.882e+08    2.1e+08      2.323      0.020    7.62e+07       9e+08\n",
      "x812       -1.091e+08   2.08e+08     -0.525      0.600   -5.17e+08    2.98e+08\n",
      "x813        3.442e+08   1.58e+08      2.182      0.029    3.51e+07    6.53e+08\n",
      "x814       -7.158e+06   1.57e+08     -0.046      0.964   -3.14e+08       3e+08\n",
      "x815        2.407e+08    1.3e+08      1.846      0.065   -1.48e+07    4.96e+08\n",
      "x816        3.799e+08   1.46e+08      2.604      0.009     9.4e+07    6.66e+08\n",
      "x817        6.144e+08   1.54e+08      3.997      0.000    3.13e+08    9.16e+08\n",
      "x818        1.023e+09   1.55e+08      6.593      0.000    7.19e+08    1.33e+09\n",
      "x819        3.537e+08   4.19e+08      0.845      0.398   -4.67e+08    1.17e+09\n",
      "x820        2.084e+08    2.2e+08      0.947      0.344   -2.23e+08     6.4e+08\n",
      "x821        1.173e+08   1.24e+08      0.950      0.342   -1.25e+08    3.59e+08\n",
      "x822        4.078e+08   2.05e+08      1.991      0.047    6.26e+06    8.09e+08\n",
      "x823       -1.481e+08   1.55e+08     -0.958      0.338   -4.51e+08    1.55e+08\n",
      "x824       -8.374e+07   1.43e+08     -0.587      0.557   -3.63e+08    1.96e+08\n",
      "x825        1.689e+08   1.24e+08      1.357      0.175    -7.5e+07    4.13e+08\n",
      "x826       -4.569e+07   1.46e+08     -0.313      0.755   -3.32e+08    2.41e+08\n",
      "x827        2.515e+08   1.22e+08      2.060      0.039    1.22e+07    4.91e+08\n",
      "x828       -5.986e+08   1.37e+08     -4.369      0.000   -8.67e+08    -3.3e+08\n",
      "x829       -1.985e+08   1.29e+08     -1.543      0.123   -4.51e+08    5.36e+07\n",
      "x830          2.5e+07   1.62e+08      0.154      0.878   -2.93e+08    3.43e+08\n",
      "x831       -5.248e+07   1.34e+08     -0.392      0.695   -3.15e+08     2.1e+08\n",
      "x832        6.313e+07   1.16e+08      0.543      0.587   -1.65e+08    2.91e+08\n",
      "x833       -2.547e+08   1.44e+08     -1.766      0.077   -5.37e+08    2.79e+07\n",
      "x834       -1.693e+08   1.45e+08     -1.166      0.244   -4.54e+08    1.15e+08\n",
      "x835        1.956e+08   1.23e+08      1.589      0.112   -4.57e+07    4.37e+08\n",
      "x836        1.685e+08   1.69e+08      0.995      0.320   -1.63e+08       5e+08\n",
      "x837         5.44e+08   1.32e+08      4.111      0.000    2.85e+08    8.03e+08\n",
      "x838         2.37e+08   1.71e+08      1.382      0.167   -9.91e+07    5.73e+08\n",
      "x839        5.768e+07   6.91e+08      0.083      0.933    -1.3e+09    1.41e+09\n",
      "x840        3.151e+08   1.63e+08      1.936      0.053   -3.88e+06    6.34e+08\n",
      "x841        3.399e+08   1.99e+08      1.706      0.088   -5.07e+07     7.3e+08\n",
      "x842       -5.411e+08   1.96e+08     -2.762      0.006   -9.25e+08   -1.57e+08\n",
      "x843       -6.499e+08   1.43e+08     -4.547      0.000    -9.3e+08    -3.7e+08\n",
      "x844       -1.464e+08   1.25e+08     -1.175      0.240   -3.91e+08    9.78e+07\n",
      "x845       -4.718e+08   2.12e+08     -2.227      0.026   -8.87e+08   -5.66e+07\n",
      "x846       -2.822e+08   1.62e+08     -1.739      0.082      -6e+08    3.58e+07\n",
      "x847       -8.412e+08   1.74e+08     -4.837      0.000   -1.18e+09      -5e+08\n",
      "x848       -2.081e+09   1.95e+08    -10.677      0.000   -2.46e+09    -1.7e+09\n",
      "x849        4.351e+08   1.57e+08      2.777      0.005    1.28e+08    7.42e+08\n",
      "x850       -1.316e+08   1.38e+08     -0.957      0.339   -4.01e+08    1.38e+08\n",
      "x851       -6.014e+08   1.43e+08     -4.191      0.000   -8.83e+08    -3.2e+08\n",
      "x852       -8.378e+08   1.39e+08     -6.040      0.000   -1.11e+09   -5.66e+08\n",
      "x853        3.581e+07   1.72e+08      0.208      0.835   -3.01e+08    3.73e+08\n",
      "x854       -8.598e+07   1.35e+08     -0.639      0.523    -3.5e+08    1.78e+08\n",
      "x855        2.058e+08   2.53e+08      0.815      0.415   -2.89e+08    7.01e+08\n",
      "x856       -6.298e+08   1.36e+08     -4.623      0.000   -8.97e+08   -3.63e+08\n",
      "x857        4.129e+07   1.43e+08      0.289      0.773   -2.39e+08    3.22e+08\n",
      "x858       -2.728e+08   1.37e+08     -1.987      0.047   -5.42e+08   -3.77e+06\n",
      "x859        -8.82e+08   1.55e+08     -5.708      0.000   -1.18e+09   -5.79e+08\n",
      "x860        -7.19e+08   1.63e+08     -4.398      0.000   -1.04e+09   -3.99e+08\n",
      "x861       -6.887e+08   1.38e+08     -4.987      0.000   -9.59e+08   -4.18e+08\n",
      "x862       -9.881e+08   1.95e+08     -5.057      0.000   -1.37e+09   -6.05e+08\n",
      "x863       -9.965e+08   1.68e+08     -5.916      0.000   -1.33e+09   -6.66e+08\n",
      "x864        2.102e+08    1.7e+08      1.233      0.217   -1.24e+08    5.44e+08\n",
      "x865        -5.03e+07   1.74e+08     -0.289      0.773   -3.92e+08    2.91e+08\n",
      "x866        -3.81e+08    1.4e+08     -2.714      0.007   -6.56e+08   -1.06e+08\n",
      "x867       -4.224e+08   1.23e+08     -3.443      0.001   -6.63e+08   -1.82e+08\n",
      "x868       -1.719e+08   1.41e+08     -1.223      0.221   -4.47e+08    1.04e+08\n",
      "x869        -4.63e+08   1.33e+08     -3.474      0.001   -7.24e+08   -2.02e+08\n",
      "x870       -1.002e+09   2.08e+08     -4.806      0.000   -1.41e+09   -5.93e+08\n",
      "x871       -7.046e+08   2.73e+08     -2.579      0.010   -1.24e+09   -1.69e+08\n",
      "x872       -6.613e+08   2.59e+08     -2.557      0.011   -1.17e+09   -1.54e+08\n",
      "x873       -1.051e+08   1.36e+08     -0.773      0.440   -3.72e+08    1.61e+08\n",
      "x874        -3.65e+08   1.61e+08     -2.269      0.023    -6.8e+08   -4.97e+07\n",
      "x875       -3.708e+08   2.72e+08     -1.364      0.173   -9.04e+08    1.62e+08\n",
      "x876       -6.123e+08   1.48e+08     -4.123      0.000   -9.03e+08   -3.21e+08\n",
      "x877       -5.469e+08    2.9e+08     -1.886      0.059   -1.12e+09    2.15e+07\n",
      "x878       -6.054e+08   1.53e+08     -3.968      0.000   -9.04e+08   -3.06e+08\n",
      "x879       -7.797e+08   1.67e+08     -4.680      0.000   -1.11e+09   -4.53e+08\n",
      "x880       -8.222e+08   1.58e+08     -5.216      0.000   -1.13e+09   -5.13e+08\n",
      "x881       -7.185e+07   1.53e+08     -0.469      0.639   -3.72e+08    2.29e+08\n",
      "x882       -7.285e+08   1.66e+08     -4.392      0.000   -1.05e+09   -4.03e+08\n",
      "x883        1.195e+08   1.46e+08      0.820      0.412   -1.66e+08    4.05e+08\n",
      "x884        3.389e+08   1.72e+08      1.971      0.049    1.86e+06    6.76e+08\n",
      "x885        -4.51e+08   2.59e+08     -1.742      0.082   -9.59e+08    5.65e+07\n",
      "x886       -1.755e+08   1.48e+08     -1.187      0.235   -4.65e+08    1.14e+08\n",
      "x887       -2.931e+08    1.4e+08     -2.096      0.036   -5.67e+08    -1.9e+07\n",
      "x888         3.35e+07   1.57e+08      0.214      0.831   -2.74e+08    3.41e+08\n",
      "x889       -1.325e+09   3.46e+08     -3.834      0.000      -2e+09   -6.48e+08\n",
      "x890       -8.983e+08    1.5e+08     -5.972      0.000   -1.19e+09   -6.03e+08\n",
      "x891       -1.744e+08    1.3e+08     -1.342      0.180   -4.29e+08    8.03e+07\n",
      "x892        4.426e+08   1.37e+08      3.236      0.001    1.75e+08    7.11e+08\n",
      "x893        5.408e+08   1.29e+08      4.203      0.000    2.89e+08    7.93e+08\n",
      "x894        1.576e+08   1.93e+08      0.816      0.414   -2.21e+08    5.36e+08\n",
      "x895       -3.389e+08   1.54e+08     -2.207      0.027    -6.4e+08   -3.79e+07\n",
      "x896       -1.041e+07   4.38e+08     -0.024      0.981   -8.68e+08    8.47e+08\n",
      "x897        -5.14e+08   1.49e+08     -3.450      0.001   -8.06e+08   -2.22e+08\n",
      "x898       -1.098e+09   1.64e+08     -6.696      0.000   -1.42e+09   -7.77e+08\n",
      "x899       -1.474e+09   1.62e+08     -9.124      0.000   -1.79e+09   -1.16e+09\n",
      "x900       -1.687e+08   1.43e+08     -1.176      0.240    -4.5e+08    1.12e+08\n",
      "x901        -1.15e+09   1.45e+08     -7.952      0.000   -1.43e+09   -8.67e+08\n",
      "x902        4.009e+08   1.72e+08      2.326      0.020    6.31e+07    7.39e+08\n",
      "x903       -1.509e+08   1.68e+08     -0.899      0.369    -4.8e+08    1.78e+08\n",
      "x904       -6.844e+07   1.55e+08     -0.440      0.660   -3.73e+08    2.36e+08\n",
      "x905       -1.368e+08   1.69e+08     -0.808      0.419   -4.69e+08    1.95e+08\n",
      "x906       -4.322e+08   1.72e+08     -2.510      0.012    -7.7e+08   -9.47e+07\n",
      "x907       -1.407e+07   3.08e+08     -0.046      0.964   -6.17e+08    5.89e+08\n",
      "x908       -1.379e+09    2.8e+08     -4.918      0.000   -1.93e+09   -8.29e+08\n",
      "x909       -1.266e+09   2.71e+08     -4.676      0.000    -1.8e+09   -7.35e+08\n",
      "x910        2.686e+08   1.48e+08      1.815      0.070   -2.15e+07    5.59e+08\n",
      "x911       -3.555e+08   1.29e+08     -2.759      0.006   -6.08e+08   -1.03e+08\n",
      "x912       -9.973e+08   1.84e+08     -5.426      0.000   -1.36e+09   -6.37e+08\n",
      "x913       -2.016e+08   1.77e+08     -1.137      0.256   -5.49e+08    1.46e+08\n",
      "x914       -1.168e+09   1.51e+08     -7.738      0.000   -1.46e+09   -8.72e+08\n",
      "x915       -5.851e+08   1.89e+08     -3.094      0.002   -9.56e+08   -2.14e+08\n",
      "x916       -6.679e+08   1.95e+08     -3.430      0.001   -1.05e+09   -2.86e+08\n",
      "x917       -1.282e+09   1.57e+08     -8.150      0.000   -1.59e+09   -9.73e+08\n",
      "x918       -4.181e+08   1.93e+08     -2.169      0.030   -7.96e+08   -4.02e+07\n",
      "x919       -2.211e+08   1.32e+08     -1.680      0.093   -4.79e+08    3.68e+07\n",
      "x920        -3.06e+08   1.39e+08     -2.203      0.028   -5.78e+08   -3.37e+07\n",
      "x921        -2.08e+08   1.83e+08     -1.133      0.257   -5.68e+08    1.52e+08\n",
      "x922       -8.843e+08   1.63e+08     -5.436      0.000    -1.2e+09   -5.65e+08\n",
      "x923       -4.171e+08   1.52e+08     -2.749      0.006   -7.15e+08    -1.2e+08\n",
      "x924       -3.708e+08   1.71e+08     -2.167      0.030   -7.06e+08   -3.54e+07\n",
      "x925        3.008e+08   1.44e+08      2.087      0.037    1.83e+07    5.83e+08\n",
      "x926       -8.659e+08   2.27e+08     -3.817      0.000   -1.31e+09   -4.21e+08\n",
      "x927       -1.292e+09   1.53e+08     -8.434      0.000   -1.59e+09   -9.92e+08\n",
      "x928       -5.235e+08   1.84e+08     -2.843      0.004   -8.84e+08   -1.63e+08\n",
      "x929       -8.659e+08    1.7e+08     -5.089      0.000    -1.2e+09   -5.32e+08\n",
      "x930       -6.876e+07   1.25e+08     -0.551      0.582   -3.13e+08    1.76e+08\n",
      "x931        2.696e+08   1.49e+08      1.815      0.070   -2.15e+07    5.61e+08\n",
      "x932        2.304e+09   1.51e+08     15.309      0.000    2.01e+09     2.6e+09\n",
      "x933        -1.13e+09   1.67e+08     -6.768      0.000   -1.46e+09   -8.02e+08\n",
      "x934       -4.352e+08   1.49e+08     -2.918      0.004   -7.27e+08   -1.43e+08\n",
      "x935        1.052e+08   1.47e+08      0.715      0.474   -1.83e+08    3.93e+08\n",
      "x936       -1.619e+08   1.75e+08     -0.923      0.356   -5.06e+08    1.82e+08\n",
      "x937         3.54e+08    1.3e+08      2.726      0.006    9.95e+07    6.08e+08\n",
      "x938        4.377e+08   1.24e+08      3.534      0.000    1.95e+08     6.8e+08\n",
      "x939       -6.506e+07   1.27e+08     -0.510      0.610   -3.15e+08    1.85e+08\n",
      "x940        -9.42e+08   1.39e+08     -6.780      0.000   -1.21e+09    -6.7e+08\n",
      "x941        3.419e+07   1.13e+08      0.301      0.763   -1.88e+08    2.57e+08\n",
      "x942        3.312e+08   1.19e+08      2.773      0.006    9.71e+07    5.65e+08\n",
      "x943        6.716e+08   1.24e+08      5.408      0.000    4.28e+08    9.15e+08\n",
      "x944        1.397e+08   1.33e+08      1.051      0.293   -1.21e+08       4e+08\n",
      "x945         1.58e+08   1.29e+08      1.223      0.221   -9.53e+07    4.11e+08\n",
      "x946       -3.523e+08   1.28e+08     -2.747      0.006   -6.04e+08   -1.01e+08\n",
      "x947       -2.891e+08   1.75e+08     -1.654      0.098   -6.32e+08    5.34e+07\n",
      "x948       -7.569e+07   1.18e+08     -0.643      0.520   -3.06e+08    1.55e+08\n",
      "x949       -4.631e+08   1.13e+08     -4.115      0.000   -6.84e+08   -2.43e+08\n",
      "x950       -4.446e+08   1.21e+08     -3.667      0.000   -6.82e+08   -2.07e+08\n",
      "x951        4.039e+08   1.35e+08      3.001      0.003     1.4e+08    6.68e+08\n",
      "x952       -5.834e+06   1.34e+08     -0.044      0.965   -2.68e+08    2.56e+08\n",
      "x953       -3.654e+08   1.22e+08     -2.993      0.003   -6.05e+08   -1.26e+08\n",
      "x954       -2.625e+07   1.28e+08     -0.205      0.838   -2.78e+08    2.25e+08\n",
      "x955         1.02e+09   1.23e+08      8.321      0.000    7.79e+08    1.26e+09\n",
      "x956       -7.179e+08   1.32e+08     -5.449      0.000   -9.76e+08    -4.6e+08\n",
      "x957       -4.981e+08   1.18e+08     -4.203      0.000    -7.3e+08   -2.66e+08\n",
      "x958        1.906e+08   1.43e+08      1.337      0.181   -8.89e+07     4.7e+08\n",
      "x959       -4.407e+08   1.43e+08     -3.089      0.002    -7.2e+08   -1.61e+08\n",
      "x960        2.419e+08   1.17e+08      2.068      0.039    1.26e+07    4.71e+08\n",
      "x961       -6.582e+08   1.31e+08     -5.033      0.000   -9.15e+08   -4.02e+08\n",
      "x962       -2.757e+08   1.34e+08     -2.056      0.040   -5.38e+08   -1.29e+07\n",
      "x963       -3.964e+07   1.28e+08     -0.309      0.757   -2.91e+08    2.11e+08\n",
      "x964        4.161e+07   1.31e+08      0.316      0.752   -2.16e+08    2.99e+08\n",
      "x965        1.851e+08   1.21e+08      1.525      0.127   -5.28e+07    4.23e+08\n",
      "x966        6.137e+07   1.61e+08      0.381      0.703   -2.54e+08    3.77e+08\n",
      "x967        -6.91e+08   3.61e+08     -1.915      0.055    -1.4e+09    1.62e+07\n",
      "x968        1.529e+08   1.42e+08      1.077      0.282   -1.25e+08    4.31e+08\n",
      "x969       -1.102e+08   1.34e+08     -0.826      0.409   -3.72e+08    1.51e+08\n",
      "x970          1.6e+08   1.47e+08      1.087      0.277   -1.29e+08    4.48e+08\n",
      "x971       -7.846e+08   1.45e+08     -5.394      0.000   -1.07e+09      -5e+08\n",
      "x972        3.535e+08   1.62e+08      2.177      0.029    3.53e+07    6.72e+08\n",
      "x973       -7.398e+08   1.43e+08     -5.161      0.000   -1.02e+09   -4.59e+08\n",
      "x974        -1.53e+08   1.26e+08     -1.216      0.224      -4e+08    9.36e+07\n",
      "x975         4.06e+08    1.2e+08      3.371      0.001     1.7e+08    6.42e+08\n",
      "x976         8.25e+07   1.22e+08      0.674      0.500   -1.57e+08    3.22e+08\n",
      "x977       -8.623e+06   1.17e+08     -0.073      0.941   -2.39e+08    2.21e+08\n",
      "x978        5.185e+08   1.13e+08      4.584      0.000    2.97e+08     7.4e+08\n",
      "x979        2.192e+08   1.37e+08      1.597      0.110   -4.99e+07    4.88e+08\n",
      "x980       -2.626e+08   1.12e+08     -2.355      0.019   -4.81e+08   -4.41e+07\n",
      "x981       -3.687e+08   1.35e+08     -2.721      0.007   -6.34e+08   -1.03e+08\n",
      "x982       -5.605e+08   1.35e+08     -4.138      0.000   -8.26e+08   -2.95e+08\n",
      "x983        3.445e+06   1.15e+08      0.030      0.976   -2.23e+08     2.3e+08\n",
      "x984        4.098e+08   1.45e+08      2.822      0.005    1.25e+08    6.95e+08\n",
      "x985       -2.825e+08   1.23e+08     -2.289      0.022   -5.24e+08   -4.06e+07\n",
      "x986       -5.371e+07   1.58e+08     -0.341      0.733   -3.63e+08    2.55e+08\n",
      "x987        3.575e+07   1.23e+08      0.290      0.772   -2.06e+08    2.78e+08\n",
      "x988       -1.488e+08   1.28e+08     -1.160      0.246      -4e+08    1.03e+08\n",
      "x989       -4.267e+08    1.3e+08     -3.284      0.001   -6.81e+08   -1.72e+08\n",
      "x990       -4.711e+08   1.34e+08     -3.521      0.000   -7.33e+08   -2.09e+08\n",
      "x991       -2.917e+08   2.94e+08     -0.992      0.321   -8.68e+08    2.85e+08\n",
      "x992       -2.215e+08   1.65e+08     -1.341      0.180   -5.45e+08    1.02e+08\n",
      "x993          1.7e+08   3.83e+08      0.444      0.657   -5.81e+08    9.21e+08\n",
      "x994        2.224e+08   1.57e+08      1.417      0.157   -8.53e+07     5.3e+08\n",
      "x995         4.12e+07   1.35e+08      0.304      0.761   -2.24e+08    3.07e+08\n",
      "x996       -7.324e+07   1.26e+08     -0.582      0.560    -3.2e+08    1.73e+08\n",
      "x997        2.211e+08   1.25e+08      1.767      0.077   -2.41e+07    4.66e+08\n",
      "x998       -2.591e+08   1.41e+08     -1.833      0.067   -5.36e+08    1.79e+07\n",
      "x999       -5.326e+07   1.15e+08     -0.464      0.643   -2.78e+08    1.72e+08\n",
      "x1000      -1.029e+08   1.47e+08     -0.700      0.484   -3.91e+08    1.85e+08\n",
      "x1001      -3.396e+08   1.35e+08     -2.508      0.012   -6.05e+08   -7.43e+07\n",
      "x1002       2.123e+05   1.35e+08      0.002      0.999   -2.64e+08    2.65e+08\n",
      "x1003      -6.793e+07   1.26e+08     -0.538      0.591   -3.16e+08     1.8e+08\n",
      "x1004       3.118e+07   1.27e+08      0.246      0.806   -2.18e+08     2.8e+08\n",
      "x1005       3.898e+08   1.44e+08      2.701      0.007    1.07e+08    6.73e+08\n",
      "x1006      -5.165e+08   1.37e+08     -3.778      0.000   -7.84e+08   -2.49e+08\n",
      "x1007       3.787e+07   1.47e+08      0.258      0.797    -2.5e+08    3.26e+08\n",
      "x1008       4.917e+08   4.78e+06    102.852      0.000    4.82e+08    5.01e+08\n",
      "x1009       3.898e+07   5.09e+06      7.653      0.000     2.9e+07     4.9e+07\n",
      "x1010       8.616e+07   5.39e+06     15.997      0.000    7.56e+07    9.67e+07\n",
      "x1011       5.492e+07   5.05e+06     10.876      0.000     4.5e+07    6.48e+07\n",
      "x1012       1.709e+08   2.84e+07      6.028      0.000    1.15e+08    2.27e+08\n",
      "x1013      -9.446e+06   2.97e+07     -0.319      0.750   -6.76e+07    4.87e+07\n",
      "x1014      -6.167e+07   1.45e+07     -4.265      0.000      -9e+07   -3.33e+07\n",
      "x1015       5.268e+07   2.41e+07      2.186      0.029    5.44e+06    9.99e+07\n",
      "x1016       4.077e+08   3.17e+07     12.848      0.000    3.46e+08     4.7e+08\n",
      "x1017      -6.277e+07   7.01e+06     -8.952      0.000   -7.65e+07    -4.9e+07\n",
      "x1018      -1.065e+08    7.4e+06    -14.387      0.000   -1.21e+08    -9.2e+07\n",
      "x1019       6.707e+07   7.96e+06      8.430      0.000    5.15e+07    8.27e+07\n",
      "x1020        2.71e+08   8.32e+06     32.572      0.000    2.55e+08    2.87e+08\n",
      "x1021        1.57e+08   1.17e+07     13.423      0.000    1.34e+08     1.8e+08\n",
      "x1022       8.187e+07   1.22e+07      6.704      0.000    5.79e+07    1.06e+08\n",
      "x1023       1.613e+08   1.07e+07     15.074      0.000     1.4e+08    1.82e+08\n",
      "x1024       3.226e+08   1.79e+07     18.020      0.000    2.88e+08    3.58e+08\n",
      "x1025       9.751e+07   1.82e+07      5.351      0.000    6.18e+07    1.33e+08\n",
      "x1026       2.557e+07   1.48e+07      1.729      0.084   -3.41e+06    5.46e+07\n",
      "x1027       4.019e+08   1.55e+07     25.866      0.000    3.71e+08    4.32e+08\n",
      "==============================================================================\n",
      "Omnibus:                   107707.836   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         51362132.730\n",
      "Skew:                           5.820   Prob(JB):                         0.00\n",
      "Kurtosis:                     119.054   Cond. No.                     2.12e+17\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.51e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#OLS summary를 보기위해 \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2, random_state=0) # y 값이 정의되지 않아 df.sales_total 으로 대체하겠습니다.\n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "Xs_train = rb.fit_transform(X_train)\n",
    "Xs_test = rb.transform(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, Xs_train)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상권코드 1010개 + 업종코드 3개 더미변수 처리 했을 때\n",
    "- 업종코드 : 외식업, 서비스업, 도소매업\n",
    "```\n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:            sales_total   R-squared:                       0.343\n",
    "Model:                            OLS   Adj. R-squared:                  0.336\n",
    "Method:                 Least Squares   F-statistic:                     45.66\n",
    "Date:                Sat, 22 Feb 2020   Prob (F-statistic):               0.00\n",
    "Time:                        11:35:33   Log-Likelihood:            -2.0350e+06\n",
    "No. Observations:               90612   AIC:                         4.072e+06\n",
    "Df Residuals:                   89586   BIC:                         4.082e+06\n",
    "Df Model:                        1025                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "==============================================================================\n",
    "Omnibus:                   107707.836   Durbin-Watson:                   2.006\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         51362132.730\n",
    "Skew:                           5.820   Prob(JB):                         0.00\n",
    "Kurtosis:                     119.054   Cond. No.                     2.12e+17\n",
    "==============================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The smallest eigenvalue is 1.51e-29. This might indicate that there are\n",
    "strong multicollinearity problems or that the design matrix is singular.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상권코드 1010개 + 업종코드 45개 더미변수 처리했을 때\n",
    "```\n",
    "  OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:            sales_total   R-squared:                       0.443\n",
    "Model:                            OLS   Adj. R-squared:                  0.436\n",
    "Method:                 Least Squares   F-statistic:                     66.62\n",
    "Date:                Sat, 15 Feb 2020   Prob (F-statistic):               0.00\n",
    "Time:                        16:13:53   Log-Likelihood:            -2.0276e+06\n",
    "No. Observations:               90612   AIC:                         4.057e+06\n",
    "Df Residuals:                   89544   BIC:                         4.067e+06\n",
    "Df Model:                        1067                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "==============================================================================\n",
    "Omnibus:                   116172.839   Durbin-Watson:                   2.007\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         85264506.370\n",
    "Skew:                           6.589   Prob(JB):                         0.00\n",
    "Kurtosis:                     152.700   Cond. No.                     1.25e+17\n",
    "==============================================================================\n",
    "\n",
    "Warnings:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The smallest eigenvalue is 4.28e-29. This might indicate that there are\n",
    "strong multicollinearity problems or that the design matrix is singular.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론) 1010개의 상권코드와 서비스코드를 원핫인코딩 하면 다중공선성이 발생한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.1939627337549884e+23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.49316595e+18, -1.77724911e+18, -1.48891493e+18, -1.72991690e+18,\n",
       "       -1.61632030e+18, -2.06310464e+18, -1.94553029e+18, -2.28336208e+18,\n",
       "       -4.54186243e+24, -6.52085910e+23])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation 실시(10회)\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict\n",
    "\n",
    "scores = cross_val_score(model, X_dum, y,scoring='neg_mean_squared_error',n_jobs=-1,cv=10)\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 시도\n",
      "0.43295550795416243\n",
      "0.46764540986097264\n",
      "==================================================\n",
      "==================================================\n",
      "2 번째 시도\n",
      "0.4512744905536025\n",
      "0.40246816411536745\n",
      "==================================================\n",
      "==================================================\n",
      "3 번째 시도\n",
      "0.44184473285831516\n",
      "0.4326529746566693\n",
      "==================================================\n",
      "==================================================\n",
      "4 번째 시도\n",
      "0.4456531746312221\n",
      "0.4127726056361403\n",
      "==================================================\n",
      "==================================================\n",
      "5 번째 시도\n",
      "0.43692286889880483\n",
      "0.4533253942535944\n",
      "==================================================\n",
      "==================================================\n",
      "6 번째 시도\n",
      "0.4449587150800643\n",
      "0.41997169592785366\n",
      "==================================================\n",
      "==================================================\n",
      "7 번째 시도\n",
      "0.44422570807458217\n",
      "0.42474832400608553\n",
      "==================================================\n",
      "==================================================\n",
      "8 번째 시도\n",
      "0.43851343442507795\n",
      "0.4433980244749468\n",
      "==================================================\n",
      "==================================================\n",
      "9 번째 시도\n",
      "0.438934419310843\n",
      "0.4467996451486497\n",
      "==================================================\n",
      "==================================================\n",
      "10 번째 시도\n",
      "0.4481330335904439\n",
      "0.4100426070548917\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2_lr = []\n",
    "MAE_lr = []\n",
    "MSE_lr = []\n",
    "RMSE_lr = []\n",
    "for i in range(10):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2) \n",
    "\n",
    "    # 로버스트 스케일링\n",
    "    rb = RobustScaler()\n",
    "    Xs_train = rb.fit_transform(X_train)\n",
    "    Xs_test = rb.transform(X_test)\n",
    "\n",
    "    # 회귀분석\n",
    "    regressor = LinearRegression()\n",
    "    model = regressor.fit(Xs_train, y_train)\n",
    "\n",
    "    print(i+1,\"번째 시도\")\n",
    "    # 정확도 결과값\n",
    "    print(model.score(Xs_train, y_train))\n",
    "    print(model.score(Xs_test, y_test))\n",
    "\n",
    "    # 오차 결과값\n",
    "    y_pred = model.predict(Xs_test)\n",
    "    R2_lr.append(r2_score(y_test , y_pred))\n",
    "    MAE_lr.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "    MSE_lr.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "    RMSE_lr.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4676454098609726, 0.40246816411536745, 0.4326529746566693, 0.41277260563614027, 0.4533253942535944, 0.41997169592785366, 0.42474832400608553, 0.4433980244749468, 0.4467996451486498, 0.4100426070548917]\n",
      "[647082035.7392398, 648679503.1301373, 644071487.905134, 634007679.8162274, 638795168.7209641, 648808333.2329934, 634857412.621154, 655537567.7177416, 641805331.6786739, 652846556.0486028]\n",
      "[1.5801062506696507e+18, 1.9052248014590863e+18, 1.543910135309669e+18, 1.405659935501998e+18, 1.6057576388806254e+18, 1.5598905701956685e+18, 1.6231874379158515e+18, 1.6300242525811876e+18, 1.450448607159404e+18, 1.7310374790547484e+18]\n",
      "[1257022772.5342333, 1380298808.7581205, 1242541804.2503314, 1185605303.421842, 1267184926.8676713, 1248955791.9300702, 1274043734.695105, 1276724031.4888678, 1204345717.4579914, 1315688975.0449185]\n"
     ]
    }
   ],
   "source": [
    "print(R2_lr)\n",
    "print(MAE_lr)\n",
    "print(MSE_lr)\n",
    "print(RMSE_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('R2_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(R2_lr, f) #피클파일 저장\n",
    "with open('MAE_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_lr, f) #피클파일 저장\n",
    "with open('MSE_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(MSE_lr, f) #피클파일 저장\n",
    "\n",
    "with open('RMSE_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(RMSE_lr, f) #피클파일 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "with open('R2_lr.pkl', 'rb') as f:\n",
    "    data = pickle.load(f) # 단 한줄씩 읽어옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시군구 OLS 업종코드 없이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw_data/df_grouped_rate.csv\", encoding ='utf-8')\n",
    "cgoongu = pd.read_csv(\"../raw_data/cgoongoo1.csv\", encoding ='utf-8')\n",
    "df_merged = pd.merge(df, cgoongu, on=['district'])\n",
    "df_merged.drop(['district','year'], axis=1, inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_store_no_of_store</th>\n",
       "      <th>s_store_no_of_opening</th>\n",
       "      <th>s_store_no_of_closing</th>\n",
       "      <th>s_work_female</th>\n",
       "      <th>s_float_male</th>\n",
       "      <th>s_float_female</th>\n",
       "      <th>b_facil_total</th>\n",
       "      <th>b_apt_avg_price</th>\n",
       "      <th>b_income_avg_monthly_inc</th>\n",
       "      <th>sales_weekday</th>\n",
       "      <th>sales_female</th>\n",
       "      <th>sales_2030s</th>\n",
       "      <th>sales_06_11</th>\n",
       "      <th>sales_11_14</th>\n",
       "      <th>sales_14_17</th>\n",
       "      <th>sales_17_21</th>\n",
       "      <th>sales_21_24</th>\n",
       "      <th>cgoongoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.707812</td>\n",
       "      <td>0.318123</td>\n",
       "      <td>0.341417</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.344443</td>\n",
       "      <td>0.164275</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>0.120878</td>\n",
       "      <td>11110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.734836</td>\n",
       "      <td>0.340414</td>\n",
       "      <td>0.468521</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.447948</td>\n",
       "      <td>0.173301</td>\n",
       "      <td>0.363921</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>11110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>0.321958</td>\n",
       "      <td>0.480098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.057219</td>\n",
       "      <td>0.227561</td>\n",
       "      <td>0.182710</td>\n",
       "      <td>11110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_store_no_of_store  s_store_no_of_opening  s_store_no_of_closing  \\\n",
       "0                 16.5                      2                      2   \n",
       "1                  2.0                      1                      1   \n",
       "2                  2.0                      0                      0   \n",
       "\n",
       "   s_work_female  s_float_male  s_float_female  b_facil_total  \\\n",
       "0           1748        211158          145498          129.0   \n",
       "1           1748        211158          145498          129.0   \n",
       "2           1748        211158          145498          129.0   \n",
       "\n",
       "   b_apt_avg_price  b_income_avg_monthly_inc  sales_weekday  sales_female  \\\n",
       "0      188530154.0                 3889111.0       0.707812      0.318123   \n",
       "1      188530154.0                 3889111.0       0.734836      0.340414   \n",
       "2      188530154.0                 3889111.0       0.914956      0.321958   \n",
       "\n",
       "   sales_2030s  sales_06_11  sales_11_14  sales_14_17  sales_17_21  \\\n",
       "0     0.341417     0.007379     0.344443     0.164275     0.345822   \n",
       "1     0.468521     0.006540     0.447948     0.173301     0.363921   \n",
       "2     0.480098     0.000000     0.524393     0.057219     0.227561   \n",
       "\n",
       "   sales_21_24  cgoongoo  \n",
       "0     0.120878     11110  \n",
       "1     0.008290     11110  \n",
       "2     0.182710     11110  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_merged.iloc[:,1:2]\n",
    "X= df_merged.drop(['sales_total'],axis=1)\n",
    "X= X.iloc[:,1:]\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s_store_no_of_store', 's_store_no_of_opening', 's_store_no_of_closing',\n",
       "       's_work_female', 's_float_male', 's_float_female', 'b_facil_total',\n",
       "       'b_apt_avg_price', 'b_income_avg_monthly_inc', 'sales_weekday',\n",
       "       'sales_female', 'sales_2030s', 'sales_06_11', 'sales_11_14',\n",
       "       'sales_14_17', 'sales_17_21', 'sales_21_24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더미변수화\n",
    "X_dum1 = pd.get_dummies(X.iloc[:,0:-1])  #district는 범주형으로 인식 안해서 따로 실시\n",
    "X_dum2 = pd.get_dummies(X.iloc[:,-1])\n",
    "X_dum = pd.concat([X_dum1, X_dum2],axis=1)\n",
    "X_dum.columns[:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS summary를 보기위해 \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2, random_state=0) # y 값이 정의되지 않아 df.sales_total 으로 대체하겠습니다.\n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "Xs_train = rb.fit_transform(X_train.iloc[:,:17])\n",
    "Xs_train = np.hstack((Xs_train, X_train.iloc[:,17:]))\n",
    "\n",
    "Xs_test = rb.transform(X_test.iloc[:,:17])\n",
    "Xs_test = np.hstack((Xs_test, X_test.iloc[:,17:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.  , 4.  , 2.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.75, 2.  , 2.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [1.25, 0.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [1.  , 1.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.75, 2.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [1.25, 1.  , 1.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            sales_total   R-squared:                       0.298\n",
      "Model:                            OLS   Adj. R-squared:                  0.298\n",
      "Method:                 Least Squares   F-statistic:                     937.4\n",
      "Date:                Sat, 22 Feb 2020   Prob (F-statistic):               0.00\n",
      "Time:                        10:36:07   Log-Likelihood:            -2.0381e+06\n",
      "No. Observations:               90612   AIC:                         4.076e+06\n",
      "Df Residuals:                   90570   BIC:                         4.077e+06\n",
      "Df Model:                          41                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          4.928e+08   4.77e+06    103.377      0.000    4.83e+08    5.02e+08\n",
      "x2          3.856e+07   5.09e+06      7.573      0.000    2.86e+07    4.85e+07\n",
      "x3          8.771e+07   5.41e+06     16.198      0.000    7.71e+07    9.83e+07\n",
      "x4            1.9e+07   2.12e+06      8.979      0.000    1.49e+07    2.31e+07\n",
      "x5          1.773e+08   1.77e+07     10.016      0.000    1.43e+08    2.12e+08\n",
      "x6         -1.556e+07   1.82e+07     -0.854      0.393   -5.13e+07    2.01e+07\n",
      "x7          -1.17e+07   6.35e+06     -1.843      0.065   -2.41e+07    7.42e+05\n",
      "x8          7.291e+07   6.29e+06     11.586      0.000    6.06e+07    8.52e+07\n",
      "x9          9.185e+07   8.75e+06     10.499      0.000    7.47e+07    1.09e+08\n",
      "x10        -8.124e+07   6.92e+06    -11.735      0.000   -9.48e+07   -6.77e+07\n",
      "x11        -1.023e+08   7.35e+06    -13.904      0.000   -1.17e+08   -8.78e+07\n",
      "x12         7.362e+07   7.53e+06      9.783      0.000    5.89e+07    8.84e+07\n",
      "x13         3.092e+08   8.25e+06     37.456      0.000    2.93e+08    3.25e+08\n",
      "x14          1.82e+08    1.1e+07     16.598      0.000    1.61e+08    2.04e+08\n",
      "x15         1.347e+08   1.23e+07     10.987      0.000    1.11e+08    1.59e+08\n",
      "x16          1.87e+08   1.05e+07     17.865      0.000    1.67e+08    2.08e+08\n",
      "x17         3.386e+08   1.73e+07     19.628      0.000    3.05e+08    3.72e+08\n",
      "x18         3.866e+08   3.52e+07     10.983      0.000    3.18e+08    4.56e+08\n",
      "x19         5.632e+07   3.65e+07      1.543      0.123   -1.52e+07    1.28e+08\n",
      "x20         2.134e+08   2.86e+07      7.472      0.000    1.57e+08    2.69e+08\n",
      "x21         1.388e+08   2.66e+07      5.218      0.000    8.67e+07    1.91e+08\n",
      "x22         2.503e+08   2.39e+07     10.495      0.000    2.04e+08    2.97e+08\n",
      "x23         2.422e+08   2.35e+07     10.327      0.000    1.96e+08    2.88e+08\n",
      "x24         2.187e+08   2.46e+07      8.906      0.000    1.71e+08    2.67e+08\n",
      "x25         2.331e+08    2.3e+07     10.153      0.000    1.88e+08    2.78e+08\n",
      "x26         2.149e+08    2.9e+07      7.418      0.000    1.58e+08    2.72e+08\n",
      "x27         3.055e+08   3.09e+07      9.872      0.000    2.45e+08    3.66e+08\n",
      "x28         3.093e+08    4.4e+07      7.030      0.000    2.23e+08    3.96e+08\n",
      "x29         3.011e+08   2.33e+07     12.945      0.000    2.55e+08    3.47e+08\n",
      "x30         3.518e+08   3.23e+07     10.899      0.000    2.89e+08    4.15e+08\n",
      "x31          2.63e+08   2.31e+07     11.367      0.000    2.18e+08    3.08e+08\n",
      "x32         2.575e+08   2.31e+07     11.132      0.000    2.12e+08    3.03e+08\n",
      "x33         2.921e+08    2.1e+07     13.886      0.000    2.51e+08    3.33e+08\n",
      "x34         3.345e+08   2.36e+07     14.160      0.000    2.88e+08    3.81e+08\n",
      "x35         2.593e+08   2.99e+07      8.667      0.000    2.01e+08    3.18e+08\n",
      "x36         1.587e+08   2.36e+07      6.733      0.000    1.13e+08    2.05e+08\n",
      "x37         2.529e+08   2.49e+07     10.141      0.000    2.04e+08    3.02e+08\n",
      "x38         2.682e+08    2.1e+07     12.762      0.000    2.27e+08    3.09e+08\n",
      "x39         2.189e+08    2.8e+07      7.813      0.000    1.64e+08    2.74e+08\n",
      "x40         2.606e+08   2.61e+07      9.965      0.000    2.09e+08    3.12e+08\n",
      "x41         3.292e+08   2.62e+07     12.565      0.000    2.78e+08    3.81e+08\n",
      "x42         1.354e+08   2.26e+07      5.989      0.000    9.11e+07     1.8e+08\n",
      "==============================================================================\n",
      "Omnibus:                   112033.679   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         59940300.571\n",
      "Skew:                           6.245   Prob(JB):                         0.00\n",
      "Kurtosis:                     128.380   Cond. No.                         31.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train, Xs_train)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 시도\n",
      "0.29585520555821143\n",
      "0.3021811033376126\n",
      "==================================================\n",
      "==================================================\n",
      "2 번째 시도\n",
      "0.29912829933685914\n",
      "0.2887702568521239\n",
      "==================================================\n",
      "==================================================\n",
      "3 번째 시도\n",
      "0.293145206423053\n",
      "0.31084343704880935\n",
      "==================================================\n",
      "==================================================\n",
      "4 번째 시도\n",
      "0.30553779097268957\n",
      "0.2615727275291474\n",
      "==================================================\n",
      "==================================================\n",
      "5 번째 시도\n",
      "0.29602814323378424\n",
      "0.30125054560180875\n",
      "==================================================\n",
      "==================================================\n",
      "6 번째 시도\n",
      "0.2959405218827035\n",
      "0.30090507770640573\n",
      "==================================================\n",
      "==================================================\n",
      "7 번째 시도\n",
      "0.29538685864599423\n",
      "0.30339785734966085\n",
      "==================================================\n",
      "==================================================\n",
      "8 번째 시도\n",
      "0.2986517564563981\n",
      "0.2895799669517868\n",
      "==================================================\n",
      "==================================================\n",
      "9 번째 시도\n",
      "0.28587048965041373\n",
      "0.3405574744221773\n",
      "==================================================\n",
      "==================================================\n",
      "10 번째 시도\n",
      "0.29360958026503803\n",
      "0.3107996652888775\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "R2_cgoongu = []\n",
    "MAE_cgoongu = []\n",
    "MSE_cgoongu = []\n",
    "RMSE_cgoongu = []\n",
    "for i in range(10):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2) \n",
    "\n",
    "    # 로버스트 스케일링\n",
    "    rb = RobustScaler()\n",
    "    Xs_train = rb.fit_transform(X_train)\n",
    "    Xs_test = rb.transform(X_test)\n",
    "\n",
    "    # 회귀분석\n",
    "    regressor = LinearRegression()\n",
    "    model = regressor.fit(Xs_train, y_train)\n",
    "\n",
    "    print(i+1,\"번째 시도\")\n",
    "    # 정확도 결과값\n",
    "    print(model.score(Xs_train, y_train))\n",
    "    print(model.score(Xs_test, y_test))\n",
    "\n",
    "    # 오차 결과값\n",
    "    y_pred = model.predict(Xs_test)\n",
    "    R2_cgoongu.append(r2_score(y_test , y_pred))\n",
    "    MAE_cgoongu.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "    MSE_cgoongu.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "    RMSE_cgoongu.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3021811033376126, 0.2887702568521239, 0.31084343704880935, 0.2615727275291474, 0.30125054560180875, 0.30090507770640573, 0.30339785734966085, 0.2895799669517868, 0.3405574744221773, 0.3107996652888775]\n",
      "[694939911.0554812, 708978451.0061802, 712084429.796848, 724656526.111685, 697818359.2263277, 716918422.8474816, 715700520.0928354, 697146892.6061007, 703104055.9643756, 710912522.6527612]\n",
      "[1.8115520541927101e+18, 2.0566219843408061e+18, 2.0845025252836155e+18, 2.159898101315176e+18, 1.9220500784553075e+18, 2.1411261537630513e+18, 1.9945879313769828e+18, 1.815766875072062e+18, 1.8864840042545754e+18, 1.9315016814667246e+18]\n",
      "[1345939097.5050507, 1434092739.1005108, 1443780636.1368113, 1469659178.624478, 1386380207.0338812, 1463258744.6391876, 1412298810.9380333, 1347503942.507057, 1373493357.9215355, 1389784760.8413055]\n"
     ]
    }
   ],
   "source": [
    "print(R2_cgoongu) \n",
    "print(MAE_cgoongu) \n",
    "print(MSE_cgoongu) \n",
    "print(RMSE_cgoongu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('R2_cgoongu.pkl', 'wb') as f:\n",
    "    pickle.dump(R2_cgoongu, f) #피클파일 저장\n",
    "with open('MAE_cgoongu.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_cgoongu, f) #피클파일 저장\n",
    "with open('MSE_cgoongu.pkl', 'wb') as f:\n",
    "    pickle.dump(MSE_cgoongu, f) #피클파일 저장\n",
    "\n",
    "with open('RMSE_cgoongu.pkl', 'wb') as f:\n",
    "    pickle.dump(RMSE_cgoongu, f) #피클파일 저장\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시군구 업종코드 3개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/df_grouped_rate.csv') #폴더 위치는 상이할 수 있음\n",
    "cgoongu = pd.read_csv(\"../raw_data/cgoongoo1.csv\", encoding ='utf-8')\n",
    "df_merged = pd.merge(df, cgoongu, on=['district'])\n",
    "df_merged.drop(['district','year'], axis=1, inplace =True)\n",
    "y=df_merged.iloc[:,1:2]\n",
    "X= df_merged.drop(['sales_total'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['service'] = X['code'].apply(lambda x: x[2:3])\n",
    "X.drop(['code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_store_no_of_store</th>\n",
       "      <th>s_store_no_of_opening</th>\n",
       "      <th>s_store_no_of_closing</th>\n",
       "      <th>s_work_female</th>\n",
       "      <th>s_float_male</th>\n",
       "      <th>s_float_female</th>\n",
       "      <th>b_facil_total</th>\n",
       "      <th>b_apt_avg_price</th>\n",
       "      <th>b_income_avg_monthly_inc</th>\n",
       "      <th>sales_weekday</th>\n",
       "      <th>sales_female</th>\n",
       "      <th>sales_2030s</th>\n",
       "      <th>sales_06_11</th>\n",
       "      <th>sales_11_14</th>\n",
       "      <th>sales_14_17</th>\n",
       "      <th>sales_17_21</th>\n",
       "      <th>sales_21_24</th>\n",
       "      <th>cgoongoo</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.707812</td>\n",
       "      <td>0.318123</td>\n",
       "      <td>0.341417</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.344443</td>\n",
       "      <td>0.164275</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>0.120878</td>\n",
       "      <td>11110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.734836</td>\n",
       "      <td>0.340414</td>\n",
       "      <td>0.468521</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.447948</td>\n",
       "      <td>0.173301</td>\n",
       "      <td>0.363921</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>11110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>0.321958</td>\n",
       "      <td>0.480098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.057219</td>\n",
       "      <td>0.227561</td>\n",
       "      <td>0.182710</td>\n",
       "      <td>11110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.640305</td>\n",
       "      <td>0.418385</td>\n",
       "      <td>0.527128</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.382012</td>\n",
       "      <td>0.211828</td>\n",
       "      <td>0.351680</td>\n",
       "      <td>0.051529</td>\n",
       "      <td>11110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1748</td>\n",
       "      <td>211158</td>\n",
       "      <td>145498</td>\n",
       "      <td>129.0</td>\n",
       "      <td>188530154.0</td>\n",
       "      <td>3889111.0</td>\n",
       "      <td>0.746605</td>\n",
       "      <td>0.469963</td>\n",
       "      <td>0.516867</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.466502</td>\n",
       "      <td>0.250264</td>\n",
       "      <td>0.270099</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>11110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_store_no_of_store  s_store_no_of_opening  s_store_no_of_closing  \\\n",
       "0                 16.5                      2                      2   \n",
       "1                  2.0                      1                      1   \n",
       "2                  2.0                      0                      0   \n",
       "3                  6.0                      1                      1   \n",
       "4                  3.5                      2                      2   \n",
       "\n",
       "   s_work_female  s_float_male  s_float_female  b_facil_total  \\\n",
       "0           1748        211158          145498          129.0   \n",
       "1           1748        211158          145498          129.0   \n",
       "2           1748        211158          145498          129.0   \n",
       "3           1748        211158          145498          129.0   \n",
       "4           1748        211158          145498          129.0   \n",
       "\n",
       "   b_apt_avg_price  b_income_avg_monthly_inc  sales_weekday  sales_female  \\\n",
       "0      188530154.0                 3889111.0       0.707812      0.318123   \n",
       "1      188530154.0                 3889111.0       0.734836      0.340414   \n",
       "2      188530154.0                 3889111.0       0.914956      0.321958   \n",
       "3      188530154.0                 3889111.0       0.640305      0.418385   \n",
       "4      188530154.0                 3889111.0       0.746605      0.469963   \n",
       "\n",
       "   sales_2030s  sales_06_11  sales_11_14  sales_14_17  sales_17_21  \\\n",
       "0     0.341417     0.007379     0.344443     0.164275     0.345822   \n",
       "1     0.468521     0.006540     0.447948     0.173301     0.363921   \n",
       "2     0.480098     0.000000     0.524393     0.057219     0.227561   \n",
       "3     0.527128     0.002456     0.382012     0.211828     0.351680   \n",
       "4     0.516867     0.007437     0.466502     0.250264     0.270099   \n",
       "\n",
       "   sales_21_24  cgoongoo service  \n",
       "0     0.120878     11110       1  \n",
       "1     0.008290     11110       1  \n",
       "2     0.182710     11110       1  \n",
       "3     0.051529     11110       1  \n",
       "4     0.005698     11110       1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cgoongoo']=X['cgoongoo'].astype('object')\n",
    "# X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미변수화\n",
    "X_dum = pd.get_dummies(X)  #district는 범주형으로 인식 안해서 따로 실시\n",
    "# X_dum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s_store_no_of_store', 's_store_no_of_opening', 's_store_no_of_closing',\n",
       "       's_work_female', 's_float_male', 's_float_female', 'b_facil_total',\n",
       "       'b_apt_avg_price', 'b_income_avg_monthly_inc', 'sales_weekday',\n",
       "       'sales_female', 'sales_2030s', 'sales_06_11', 'sales_11_14',\n",
       "       'sales_14_17', 'sales_17_21', 'sales_21_24', 'cgoongoo_11110',\n",
       "       'cgoongoo_11140', 'cgoongoo_11170', 'cgoongoo_11200', 'cgoongoo_11215',\n",
       "       'cgoongoo_11230', 'cgoongoo_11260', 'cgoongoo_11290', 'cgoongoo_11305',\n",
       "       'cgoongoo_11320', 'cgoongoo_11350', 'cgoongoo_11380', 'cgoongoo_11410',\n",
       "       'cgoongoo_11440', 'cgoongoo_11470', 'cgoongoo_11500', 'cgoongoo_11530',\n",
       "       'cgoongoo_11545', 'cgoongoo_11560', 'cgoongoo_11590', 'cgoongoo_11620',\n",
       "       'cgoongoo_11650', 'cgoongoo_11680', 'cgoongoo_11710', 'cgoongoo_11740',\n",
       "       'service_1', 'service_2', 'service_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dum.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            sales_total   R-squared:                       0.298\n",
      "Model:                            OLS   Adj. R-squared:                  0.298\n",
      "Method:                 Least Squares   F-statistic:                     937.4\n",
      "Date:                Sat, 22 Feb 2020   Prob (F-statistic):               0.00\n",
      "Time:                        12:00:03   Log-Likelihood:            -2.0381e+06\n",
      "No. Observations:               90612   AIC:                         4.076e+06\n",
      "Df Residuals:                   90570   BIC:                         4.077e+06\n",
      "Df Model:                          41                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          4.928e+08   4.77e+06    103.377      0.000    4.83e+08    5.02e+08\n",
      "x2          3.856e+07   5.09e+06      7.573      0.000    2.86e+07    4.85e+07\n",
      "x3          8.771e+07   5.41e+06     16.198      0.000    7.71e+07    9.83e+07\n",
      "x4            1.9e+07   2.12e+06      8.979      0.000    1.49e+07    2.31e+07\n",
      "x5          1.773e+08   1.77e+07     10.016      0.000    1.43e+08    2.12e+08\n",
      "x6         -1.556e+07   1.82e+07     -0.854      0.393   -5.13e+07    2.01e+07\n",
      "x7          -1.17e+07   6.35e+06     -1.843      0.065   -2.41e+07    7.42e+05\n",
      "x8          7.291e+07   6.29e+06     11.586      0.000    6.06e+07    8.52e+07\n",
      "x9          9.185e+07   8.75e+06     10.499      0.000    7.47e+07    1.09e+08\n",
      "x10        -8.124e+07   6.92e+06    -11.735      0.000   -9.48e+07   -6.77e+07\n",
      "x11        -1.023e+08   7.35e+06    -13.904      0.000   -1.17e+08   -8.78e+07\n",
      "x12         7.362e+07   7.53e+06      9.783      0.000    5.89e+07    8.84e+07\n",
      "x13         3.092e+08   8.25e+06     37.456      0.000    2.93e+08    3.25e+08\n",
      "x14          1.82e+08    1.1e+07     16.598      0.000    1.61e+08    2.04e+08\n",
      "x15         1.347e+08   1.23e+07     10.987      0.000    1.11e+08    1.59e+08\n",
      "x16          1.87e+08   1.05e+07     17.865      0.000    1.67e+08    2.08e+08\n",
      "x17         3.386e+08   1.73e+07     19.628      0.000    3.05e+08    3.72e+08\n",
      "x18         3.866e+08   3.52e+07     10.983      0.000    3.18e+08    4.56e+08\n",
      "x19         5.632e+07   3.65e+07      1.543      0.123   -1.52e+07    1.28e+08\n",
      "x20         2.134e+08   2.86e+07      7.472      0.000    1.57e+08    2.69e+08\n",
      "x21         1.388e+08   2.66e+07      5.218      0.000    8.67e+07    1.91e+08\n",
      "x22         2.503e+08   2.39e+07     10.495      0.000    2.04e+08    2.97e+08\n",
      "x23         2.422e+08   2.35e+07     10.327      0.000    1.96e+08    2.88e+08\n",
      "x24         2.187e+08   2.46e+07      8.906      0.000    1.71e+08    2.67e+08\n",
      "x25         2.331e+08    2.3e+07     10.153      0.000    1.88e+08    2.78e+08\n",
      "x26         2.149e+08    2.9e+07      7.418      0.000    1.58e+08    2.72e+08\n",
      "x27         3.055e+08   3.09e+07      9.872      0.000    2.45e+08    3.66e+08\n",
      "x28         3.093e+08    4.4e+07      7.030      0.000    2.23e+08    3.96e+08\n",
      "x29         3.011e+08   2.33e+07     12.945      0.000    2.55e+08    3.47e+08\n",
      "x30         3.518e+08   3.23e+07     10.899      0.000    2.89e+08    4.15e+08\n",
      "x31          2.63e+08   2.31e+07     11.367      0.000    2.18e+08    3.08e+08\n",
      "x32         2.575e+08   2.31e+07     11.132      0.000    2.12e+08    3.03e+08\n",
      "x33         2.921e+08    2.1e+07     13.886      0.000    2.51e+08    3.33e+08\n",
      "x34         3.345e+08   2.36e+07     14.160      0.000    2.88e+08    3.81e+08\n",
      "x35         2.593e+08   2.99e+07      8.667      0.000    2.01e+08    3.18e+08\n",
      "x36         1.587e+08   2.36e+07      6.733      0.000    1.13e+08    2.05e+08\n",
      "x37         2.529e+08   2.49e+07     10.141      0.000    2.04e+08    3.02e+08\n",
      "x38         2.682e+08    2.1e+07     12.762      0.000    2.27e+08    3.09e+08\n",
      "x39         2.189e+08    2.8e+07      7.813      0.000    1.64e+08    2.74e+08\n",
      "x40         2.606e+08   2.61e+07      9.965      0.000    2.09e+08    3.12e+08\n",
      "x41         3.292e+08   2.62e+07     12.565      0.000    2.78e+08    3.81e+08\n",
      "x42         1.354e+08   2.26e+07      5.989      0.000    9.11e+07     1.8e+08\n",
      "==============================================================================\n",
      "Omnibus:                   112033.679   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         59940300.571\n",
      "Skew:                           6.245   Prob(JB):                         0.00\n",
      "Kurtosis:                     128.380   Cond. No.                         31.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#OLS summary를 보기위해 \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dum, y, test_size=0.2, random_state=0) # y 값이 정의되지 않아 df.sales_total 으로 대체하겠습니다.\n",
    "# 로버스트 스케일링\n",
    "rb = RobustScaler()\n",
    "# Xs_train = rb.fit_transform(X_train.iloc[:,:17])\n",
    "# Xs_train = np.hstack((Xs_train, X_train.iloc[:,17:]))\n",
    "\n",
    "# Xs_test = rb.transform(X_test.iloc[:,:17])\n",
    "# Xs_test = np.hstack((Xs_test, X_test.iloc[:,17:]))\n",
    "Xs_train = rb.fit_transform(X_train.iloc[:,:-3])\n",
    "Xs_test = rb.transform(X_test.iloc[:,:-3])\n",
    "\n",
    "model = sm.OLS(y_train, Xs_train)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (상권코드 1010개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('../raw_data/df_grouped_rate.csv') #폴더 위치는 상이할 수 있음\n",
    "y=df.iloc[:,3:4]\n",
    "X= df.iloc[:,1:].drop(['sales_total'],axis=1)\n",
    "# 더미변수화\n",
    "X_dum1 = pd.get_dummies(X.iloc[:,0])  #district는 범주형으로 인식 안해서 따로 실시\n",
    "X_dum2 = pd.get_dummies(X.iloc[:,1:])\n",
    "X = pd.concat([X_dum1, X_dum2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 시도\n",
      "0.8855539537969531\n",
      "0.7123008661778889\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 번째 시도\n",
      "0.8877133339202862\n",
      "0.7000830569701366\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 번째 시도\n",
      "0.8813754523643749\n",
      "0.7292598113397541\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 번째 시도\n",
      "0.8852109722581207\n",
      "0.7191962331516705\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 번째 시도\n",
      "0.886348781258642\n",
      "0.692337388176013\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 번째 시도\n",
      "0.8832207843512278\n",
      "0.7107033500590044\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 번째 시도\n",
      "0.8841753739144583\n",
      "0.7135588304672187\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 번째 시도\n",
      "0.8800700554929304\n",
      "0.6994841394350301\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 번째 시도\n",
      "0.8871357493317835\n",
      "0.7142729852698322\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 번째 시도\n",
      "0.8884251082730303\n",
      "0.6934375074159209\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "R2_RF = []\n",
    "MAE_RF = []\n",
    "MSE_RF = []\n",
    "RMSE_RF = []\n",
    "for i in range(10):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    Xs_train = X_train\n",
    "    Xs_test = X_test\n",
    "    regr = RandomForestRegressor(n_estimators=50,max_depth=20, n_jobs=-1)\n",
    "    model=regr.fit(Xs_train, y_train)\n",
    "    y_pred=model.predict(Xs_test)\n",
    "    \n",
    "    print(i+1,\"번째 시도\")\n",
    "    # 정확도 결과값\n",
    "    print(model.score(Xs_train, y_train))\n",
    "    print(model.score(Xs_test, y_test))\n",
    "\n",
    "    # 오차 결과값\n",
    "    R2_RF.append(r2_score(y_test , y_pred))\n",
    "    MAE_RF.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "    MSE_RF.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "    RMSE_RF.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7123008661778889, 0.7000830569701366, 0.7292598113397541, 0.7191962331516705, 0.692337388176013, 0.7107033500590043, 0.7135588304672187, 0.6994841394350301, 0.7142729852698322, 0.6934375074159209]\n",
      "[449785112.6294148, 446212734.7671297, 447890754.86098444, 451625667.5133701, 445865890.12949145, 442355273.1377831, 446089670.0951218, 447415163.7190714, 445434133.4830528, 437294514.8725618]\n",
      "[8.265276739061085e+17, 8.120435978355119e+17, 8.2239566534996e+17, 8.091070983962254e+17, 8.547321165231905e+17, 8.261774271114982e+17, 8.443124401772238e+17, 9.201507632837652e+17, 8.038788677680585e+17, 8.06667925760289e+17]\n",
      "[909135674.0916663, 901134616.9332925, 906860333.9820085, 899503806.7713919, 924517234.302958, 908943027.4288363, 918864756.1949602, 959244892.2375168, 896592921.9930629, 898146939.9604326]\n"
     ]
    }
   ],
   "source": [
    "print(R2_RF) \n",
    "print(MAE_RF) \n",
    "print(MSE_RF) \n",
    "print(RMSE_RF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pkl_files/R2_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(R2_RF, f) #피클파일 저장\n",
    "with open('pkl_files/MAE_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_lr, f) #피클파일 저장\n",
    "    \n",
    "########## 이름 잘못 적었따 ㅠㅠㅠㅠ\n",
    "with open('pkl_files/MSE_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(MSE_RF, f) #피클파일 저장\n",
    "\n",
    "with open('pkl_files/RMSE_RF.pkl', 'wb') as f:\n",
    "    pickle.dump(RMSE_RF, f) #피클파일 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (시군구)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../raw_data/df_grouped_rate.csv\", encoding ='utf-8')\n",
    "cgoongu = pd.read_csv(\"../raw_data/cgoongoo1.csv\", encoding ='utf-8')\n",
    "df_merged = pd.merge(df, cgoongu, on=['district'])\n",
    "df_merged.drop(['district','year'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "y=df_merged.iloc[:,1:2]\n",
    "X= df_merged.drop(['sales_total'],axis=1)\n",
    "# X.columns\n",
    "# 더미변수화\n",
    "X_dum1 = pd.get_dummies(X.iloc[:,0:-1])  #district는 범주형으로 인식 안해서 따로 실시\n",
    "X_dum2 = pd.get_dummies(X.iloc[:,-1])\n",
    "X = pd.concat([X_dum1, X_dum2],axis=1)\n",
    "# X_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 시도\n",
      "0.8998467497578891\n",
      "0.6802226302816198\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 번째 시도\n",
      "0.9020416064994576\n",
      "0.6683817661895358\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 번째 시도\n",
      "0.9013659344519755\n",
      "0.6774419178919397\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 번째 시도\n",
      "0.8997279576297758\n",
      "0.6622113532206795\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 번째 시도\n",
      "0.903915255827739\n",
      "0.6523103043284098\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 번째 시도\n",
      "0.8998290666922715\n",
      "0.6716634130220733\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 번째 시도\n",
      "0.9041537187887163\n",
      "0.6578239046395441\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 번째 시도\n",
      "0.8994470332253633\n",
      "0.6878557999495694\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 번째 시도\n",
      "0.9051449096029229\n",
      "0.6593712829737952\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 번째 시도\n",
      "0.9015410527355165\n",
      "0.6784010416389705\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np \n",
    "\n",
    "R2_RF_c = []\n",
    "MAE_RF_c = []\n",
    "MSE_RF_c = []\n",
    "RMSE_RF_c = []\n",
    "for i in range(10):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    Xs_train = X_train\n",
    "    Xs_test = X_test\n",
    "    regr = RandomForestRegressor(n_estimators=50,max_depth=20, n_jobs=-1)\n",
    "    model=regr.fit(Xs_train, y_train)\n",
    "    y_pred=model.predict(Xs_test)\n",
    "    \n",
    "    print(i+1,\"번째 시도\")\n",
    "    # 정확도 결과값\n",
    "    print(model.score(Xs_train, y_train))\n",
    "    print(model.score(Xs_test, y_test))\n",
    "\n",
    "    # 오차 결과값\n",
    "    R2_RF_c.append(r2_score(y_test , y_pred))\n",
    "    MAE_RF_c.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "    MSE_RF_c.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "    RMSE_RF_c.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6802226302816198, 0.6683817661895358, 0.6774419178919397, 0.6622113532206795, 0.6523103043284098, 0.6716634130220733, 0.6578239046395441, 0.6878557999495694, 0.6593712829737952, 0.6784010416389705]\n",
      "[454503927.4785681, 455461946.7784578, 456022726.0518362, 459388121.43013835, 453582089.42480946, 457196495.6549004, 451462806.02449113, 457738810.23634917, 456390577.3145367, 464367556.78221273]\n",
      "[9.064740617367328e+17, 9.338313240838047e+17, 9.988792121759087e+17, 1.0294519119889932e+18, 9.961150129492637e+17, 8.98943692568813e+17, 9.280117372720316e+17, 9.124766364279164e+17, 8.606323753026831e+17, 9.081914697825079e+17]\n",
      "[952089313.9494492, 966349483.4084637, 999439448.9792309, 1014619096.9960072, 998055616.1603739, 948126411.7030034, 963333658.330296, 955236429.5963154, 927702740.8080043, 952990802.5697352]\n"
     ]
    }
   ],
   "source": [
    "print(R2_RF_c) \n",
    "print(MAE_RF_c) \n",
    "print(MSE_RF_c) \n",
    "print(RMSE_RF_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pkl_files/R2_RF_c.pkl', 'wb') as f:\n",
    "    pickle.dump(R2_RF_c, f) #피클파일 저장\n",
    "with open('pkl_files/MAE_RF_c.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_RF_c, f) #피클파일 저장\n",
    "with open('pkl_files/MSE_RF_c.pkl', 'wb') as f:\n",
    "    pickle.dump(MSE_RF_c, f) #피클파일 저장\n",
    "\n",
    "with open('pkl_files/MSE_RF_c.pkl', 'wb') as f:\n",
    "    pickle.dump(RMSE_RF_c, f) #피클파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Fores dummy 변수?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM (1010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('../raw_data/df_grouped_rate.csv') #폴더 위치는 상이할 수 있음\n",
    "y=df.iloc[:,3:4]\n",
    "X= df.iloc[:,1:].drop(['sales_total'],axis=1)\n",
    "# 더미변수화\n",
    "X_dum1 = pd.get_dummies(X.iloc[:,0])  #district는 범주형으로 인식 안해서 따로 실시\n",
    "X_dum2 = pd.get_dummies(X.iloc[:,1:])\n",
    "X = pd.concat([X_dum1, X_dum2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 시도\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d8aed4f139fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"번째 시도\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# 정확도 결과값\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "R2_lgb_gbdt = []\n",
    "MAE_lgb_gbdt = []\n",
    "MSE_lgb_gbdt = []\n",
    "RMSE_lgb_gbdt = []\n",
    "for i in range(10):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators=100, max_depth=1, random_state=0)\n",
    "    predict_train = model.predict(train_x)\n",
    "    predict_test = model.predict(test_x)model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "    params = {'learning_rate': 0.01, \n",
    "              'max_depth': 16, \n",
    "              'boosting': 'gbdt', \n",
    "              'objective': 'regression', \n",
    "              'metric': 'mse', \n",
    "              'is_training_metric': True, \n",
    "              'num_leaves': 144, \n",
    "              'feature_fraction': 0.9, \n",
    "              'bagging_fraction': 0.7, \n",
    "              'bagging_freq': 5, \n",
    "              'device': 'cpu'\n",
    "             }\n",
    "    print(i+1,\"번째 시도\")\n",
    "    # 정확도 결과값\n",
    "    print(model.score(Xs_train, y_train))\n",
    "    print(model.score(Xs_test, y_test))\n",
    "\n",
    "    # 오차 결과값\n",
    "    R2_lgb_gbdt.append(r2_score(y_test , y_pred))\n",
    "    MAE_lgb_gbdt.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "    MSE_lgb_gbdt.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "    RMSE_lgb_gbdt.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('='*50)\n",
    "    print('='*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705, 0.6784010416389705]\n",
      "[464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273, 464367556.78221273]\n",
      "[9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17, 9.081914697825079e+17]\n",
      "[952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352, 952990802.5697352]\n"
     ]
    }
   ],
   "source": [
    "print(R2_lgb_gbdt) \n",
    "print(MAE_lgb_gbdt) \n",
    "print(MSE_lgb_gbdt) \n",
    "print(RMSE_lgb_gbdt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pkl_files/R2_lgb_gbdt.pkl', 'wb') as f:\n",
    "    pickle.dump(R2_lgb_gbdt, f) #피클파일 저장\n",
    "with open('pkl_files/MAE_lgb_gbdt.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_lgb_gbdt, f) #피클파일 저장\n",
    "with open('pkl_files/MSE_lgb_gbdt.pkl', 'wb') as f:\n",
    "    pickle.dump(MSE_lgb_gbdt, f) #피클파일 저장\n",
    "\n",
    "with open('pkl_files/RMSE_lgb_gbdt.pkl', 'wb') as f:\n",
    "    pickle.dump(RMSE_lgb_gbdt, f) #피클파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine predictors using stacking\n",
    "y_pred, y_test\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
